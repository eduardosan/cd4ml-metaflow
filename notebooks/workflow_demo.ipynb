{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b87a9d-e5fd-49d4-9744-d8585153245c",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is a demo on how to setup a basic Workflow to Work with Jupyter Notebooks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5765458-509c-4200-a54f-fe22fa2d7a04",
   "metadata": {},
   "source": [
    "## Setup project\n",
    "\n",
    "For project setup we will use [poetry](https://python-poetry.org/docs/) as dependency management tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0753bd3a-73a6-48c8-9229-e01c21639c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../')\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a7bc2d-7d07-4a4d-bc9e-a00d269ca31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-28 18:45:48--  https://install.python-poetry.org/\n",
      "Resolving install.python-poetry.org (install.python-poetry.org)... 76.76.21.164, 76.76.21.22\n",
      "Connecting to install.python-poetry.org (install.python-poetry.org)|76.76.21.164|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 28457 (28K) [text/plain]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "-                   100%[===================>]  27.79K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2022-11-28 18:45:48 (15.5 MB/s) - written to stdout [28457/28457]\n",
      "\n",
      "\u001b[36mRetrieving Poetry metadata\u001b[0m\n",
      "\n",
      "The latest version (\u001b[1m1.2.2\u001b[0m) is already installed.\n"
     ]
    }
   ],
   "source": [
    "!wget -O - https://install.python-poetry.org | python3 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1937c067-eeee-4b7b-8be1-5e74b841da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/home/jovyan/.local/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441f3d28-1d0a-4686-a58b-2d522f8a6e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[39;1mPoetry\u001b[39;22m (version \u001b[36m1.2.2\u001b[39m)\n"
     ]
    }
   ],
   "source": [
    "!poetry --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fcfc44-dead-41a5-a01b-5a21bc341a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "os.environ['PYTHON_BIN'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fca480b-43d9-4aa7-ae7c-acabb6c030df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[39;1mVirtualenv\u001b[39;22m\n",
      "\u001b[34mPython\u001b[39m:         \u001b[32m3.10.6\u001b[39m\n",
      "\u001b[34mImplementation\u001b[39m: \u001b[32mCPython\u001b[39m\n",
      "\u001b[34mPath\u001b[39m:           \u001b[32m/home/jovyan/.cache/pypoetry/virtualenvs/cd4ml-8EXZSVYp-py3.10\u001b[39m\n",
      "\u001b[34mExecutable\u001b[39m:     \u001b[32m/home/jovyan/.cache/pypoetry/virtualenvs/cd4ml-8EXZSVYp-py3.10/bin/python\u001b[39m\n",
      "\u001b[34mValid\u001b[39m:          \u001b[32mTrue\u001b[39m\n",
      "\n",
      "\u001b[39;1mSystem\u001b[39;22m\n",
      "\u001b[34mPlatform\u001b[39m:   \u001b[32mlinux\u001b[39m\n",
      "\u001b[34mOS\u001b[39m:         \u001b[32mposix\u001b[39m\n",
      "\u001b[34mPython\u001b[39m:     \u001b[32m3.10.6\u001b[39m\n",
      "\u001b[34mPath\u001b[39m:       \u001b[32m/opt/conda\u001b[39m\n",
      "\u001b[34mExecutable\u001b[39m: \u001b[32m/opt/conda/bin/python3.10\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!poetry env info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a252abb-2dd2-4274-85d7-d52bd32f6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry env use system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0570c706-81ab-4acf-b271-86b6cb045503",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry config virtualenvs.create false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828dc105-148f-4866-9a0c-dae039eb2ec6",
   "metadata": {},
   "source": [
    "### Initialize project \n",
    "\n",
    "This will generate the structure necessary to run data science jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bf45441-9b2e-4966-922f-4766fe3ad96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure here package information that will be put in Poetry configuration\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['NAME'] = \"cd4ml\"\n",
    "os.environ['DESCRIPTION'] = \"Data science experiment tutorial\"\n",
    "os.environ['PYTHON'] = f\"{sys.version_info[0]}.{sys.version_info[1]}.{sys.version_info[2]}\"\n",
    "os.environ['AUTHOR'] = \"Eduardo Santos <eduardo.santos@thoughtworks.com>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9ce773-b3b1-40f2-9bc5-d665b2586b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31;1mA pyproject.toml file with a poetry section already exists.\u001b[39;22m\n"
     ]
    }
   ],
   "source": [
    "!poetry init --name=\"$NAME\" --description=\"$DESCRIPTION\" --python=\"$PYTHON\" --author=\"$AUTHOR\" --no-interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c5a02d-17bc-4a1e-86d8-7c0a3fa18569",
   "metadata": {},
   "source": [
    "You can see generated file clicking here: [pyproject.toml](../pyproject.toml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a387bae3-b1da-48c1-93cc-c52b0163ad3c",
   "metadata": {},
   "source": [
    "### Generate project structure\n",
    "\n",
    "We are going to use as reference the [data science cookiecutter template](https://drivendata.github.io/cookiecutter-data-science/), which folllows this standard:\n",
    "\n",
    "```\n",
    "├── LICENSE\n",
    "├── Makefile           <- Makefile with commands like `make data` or `make train`\n",
    "├── README.md          <- The top-level README for developers using this project.\n",
    "├── data\n",
    "│   ├── external       <- Data from third party sources.\n",
    "│   ├── interim        <- Intermediate data that has been transformed.\n",
    "│   ├── processed      <- The final, canonical data sets for modeling.\n",
    "│   └── raw            <- The original, immutable data dump.\n",
    "│\n",
    "├── docs               <- A default Sphinx project; see sphinx-doc.org for details\n",
    "│\n",
    "├── models             <- Trained and serialized models, model predictions, or model summaries\n",
    "│\n",
    "├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n",
    "│                         the creator's initials, and a short `-` delimited description, e.g.\n",
    "│                         `1.0-jqp-initial-data-exploration`.\n",
    "│\n",
    "├── references         <- Data dictionaries, manuals, and all other explanatory materials.\n",
    "│\n",
    "├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n",
    "│   └── figures        <- Generated graphics and figures to be used in reporting\n",
    "│\n",
    "├── pyproject.toml     <- Poetry configuration file\n",
    "│\n",
    "├── setup.py           <- makes project pip installable (pip install -e .) so src can be imported\n",
    "├── src                <- Source code for use in this project.\n",
    "│   ├── __init__.py    <- Makes src a Python module\n",
    "│   │\n",
    "│   ├── data           <- Scripts to download or generate data\n",
    "│   │   └── make_dataset.py\n",
    "│   │\n",
    "│   ├── features       <- Scripts to turn raw data into features for modeling\n",
    "│   │   └── build_features.py\n",
    "│   │\n",
    "│   ├── models         <- Scripts to train models and then use trained models to make\n",
    "│   │   │                 predictions\n",
    "│   │   ├── predict_model.py\n",
    "│   │   └── train_model.py\n",
    "│   │\n",
    "│   └── visualization  <- Scripts to create exploratory and results oriented visualizations\n",
    "│       └── visualize.py\n",
    "│\n",
    "└── tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io\n",
    "```\n",
    "\n",
    "For now we just need the directories that will hold the data code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c739ab2-6629-4f05-8a10-816d9653dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p src/data\n",
    "!touch src/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef3fe0-4661-49e2-ab6c-d3bb9b2d0bb9",
   "metadata": {},
   "source": [
    "## Data extraction\n",
    "\n",
    "For this example we will download some news feed data to use as a dataset. As this is an introductory example just a few news will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9c51de-4f46-40bd-b458-9eec5f083f9b",
   "metadata": {},
   "source": [
    "### Download data\n",
    "\n",
    "The goal is to create the case as a multistep feature extraction. First step is to create a function to download data from a service provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73da7085-bc15-4d7e-abc7-25ab3d36c0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following packages are already present in the pyproject.toml and will be skipped:\n",
      "\n",
      "  • \u001b[36mfeedparser\u001b[39m\n",
      "  • \u001b[36mpandas\u001b[39m\n",
      "  • \u001b[36mmetaflow\u001b[39m\n",
      "\n",
      "If you want to update it to the latest compatible version, you can use `poetry update package`.\n",
      "If you prefer to upgrade it to the latest available version, you can use `poetry add package@latest`.\n",
      "\n",
      "Nothing to add.\n"
     ]
    }
   ],
   "source": [
    "!poetry add feedparser pandas metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1269566-6f4c-4da3-a969-e1a07fe8e0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring colorama: markers 'sys_platform == \"win32\" and python_full_version == \"3.10.6\"' don't match your environment\n",
      "Collecting astroid==2.12.13\n",
      "  Using cached astroid-2.12.13-py3-none-any.whl (264 kB)\n",
      "Collecting boto3==1.26.17\n",
      "  Downloading boto3-1.26.17-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting botocore==1.29.17\n",
      "  Downloading botocore-1.29.17-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi==2022.9.24 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer==2.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.1.1)\n",
      "Collecting dill==0.3.6\n",
      "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Collecting feedparser==6.0.10\n",
      "  Using cached feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: idna==3.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (3.4)\n",
      "Collecting isort==5.10.1\n",
      "  Using cached isort-5.10.1-py3-none-any.whl (103 kB)\n",
      "Collecting jmespath==1.0.1\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting lazy-object-proxy==1.8.0\n",
      "  Using cached lazy-object-proxy-1.8.0.tar.gz (41 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting mccabe==0.7.0\n",
      "  Using cached mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
      "Collecting metaflow==2.7.14\n",
      "  Using cached metaflow-2.7.14-py2.py3-none-any.whl (853 kB)\n",
      "Collecting numpy==1.23.5\n",
      "  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (13.9 MB)\n",
      "Collecting pandas==1.5.2\n",
      "  Downloading pandas-1.5.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (11.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting platformdirs==2.5.4\n",
      "  Using cached platformdirs-2.5.4-py3-none-any.whl (14 kB)\n",
      "Collecting pylint==2.15.6\n",
      "  Using cached pylint-2.15.6-py3-none-any.whl (508 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 123)) (2.8.2)\n",
      "Collecting pytz==2022.6\n",
      "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests==2.28.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 129)) (2.28.1)\n",
      "Collecting s3transfer==0.6.0\n",
      "  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "Collecting sgmllib3k==1.0.0\n",
      "  Using cached sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six==1.16.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 137)) (1.16.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 140)) (2.0.1)\n",
      "Collecting tomlkit==0.11.6\n",
      "  Using cached tomlkit-0.11.6-py3-none-any.whl (35 kB)\n",
      "Collecting urllib3==1.26.13\n",
      "  Using cached urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "Collecting wrapt==1.14.1\n",
      "  Using cached wrapt-1.14.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (78 kB)\n",
      "Building wheels for collected packages: lazy-object-proxy, sgmllib3k\n",
      "  Building wheel for lazy-object-proxy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lazy-object-proxy: filename=lazy_object_proxy-1.8.0-cp310-cp310-linux_aarch64.whl size=11299 sha256=88c082d31e23404a118767b9cdd9e70a6bb8293b899e23f7fdab0e712ecd8f76\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/0f/87/53/4a8ff2034f38ce1f3f2d993f3d05dada6fc36fadc7792ad6b1\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6048 sha256=f0664a398d9c8cd8e9c67c19d704fb8e98c2d53d90d8595c8bf3a7bfbdd69e0c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/3b/24/68/f82c1fe16fe6cc7c6f9f67fe4bbf2a4ce527dea6b14a4b34ee\n",
      "Successfully built lazy-object-proxy sgmllib3k\n",
      "Installing collected packages: sgmllib3k, pytz, wrapt, urllib3, tomlkit, platformdirs, numpy, mccabe, lazy-object-proxy, jmespath, isort, feedparser, dill, pandas, botocore, astroid, s3transfer, pylint, boto3, metaflow\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2022.5\n",
      "    Uninstalling pytz-2022.5:\n",
      "      Successfully uninstalled pytz-2022.5\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.11\n",
      "    Uninstalling urllib3-1.26.11:\n",
      "      Successfully uninstalled urllib3-1.26.11\n",
      "Successfully installed astroid-2.12.13 boto3-1.26.17 botocore-1.29.17 dill-0.3.6 feedparser-6.0.10 isort-5.10.1 jmespath-1.0.1 lazy-object-proxy-1.8.0 mccabe-0.7.0 metaflow-2.7.14 numpy-1.23.5 pandas-1.5.2 platformdirs-2.5.4 pylint-2.15.6 pytz-2022.6 s3transfer-0.6.0 sgmllib3k-1.0.0 tomlkit-0.11.6 urllib3-1.26.13 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!poetry export -f requirements.txt --output requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3958d612-f13f-4b6e-b598-3a3d6d66560b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>LINK</th>\n",
       "      <th>TIME_PUBLISHED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perfil da PM em SC curte posts antidemocrático...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/hHaPhjo7AiNLn-...</td>\n",
       "      <td>https://g1.globo.com/sc/santa-catarina/noticia...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:39:29 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ponte que liga Toca da Onça a Rio Bonito é rec...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/iA1ARsUvBzuFOH...</td>\n",
       "      <td>https://g1.globo.com/rj/regiao-serrana/noticia...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:39:25 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Menina denuncia estupro à professora e ex-padr...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/DsJJ0ftZ_UF0g9...</td>\n",
       "      <td>https://g1.globo.com/go/goias/noticia/2022/11/...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:38:07 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Treinador é preso no meio de partida de handeb...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/lGTqe75_EueDyo...</td>\n",
       "      <td>https://g1.globo.com/sc/santa-catarina/noticia...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:36:53 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Presidente da Associação de Catadoras e Catado...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/MOruxIfu5xe5ku...</td>\n",
       "      <td>https://g1.globo.com/se/sergipe/noticia/2022/1...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:33:29 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VÍDEOS: AB1 de segunda-feira, 28 de novembro</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/QHEuQoE9N98BI0...</td>\n",
       "      <td>https://g1.globo.com/pe/caruaru-regiao/edicao/...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:31:45 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Homem matou ex com um tiro na cabeça em frente...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/VYG-_GYfr3uh6U...</td>\n",
       "      <td>https://g1.globo.com/rs/rio-grande-do-sul/noti...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:31:31 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mulher leva tiro na cabeça enquanto assistia j...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/Af4Z8E2f5SH5N5...</td>\n",
       "      <td>https://g1.globo.com/to/tocantins/noticia/2022...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:31:08 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cresol constitui cooperativa no Mato Grosso</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/kwDswG7_VnwyUz...</td>\n",
       "      <td>https://g1.globo.com/pr/parana/especial-public...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:30:12 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Espetáculo 'Cabaré Chinelo' encerra temporada ...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/am3JENH4WLtILA...</td>\n",
       "      <td>https://g1.globo.com/am/amazonas/noticia/2022/...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:30:08 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Novembro se encerra com céu parcialmente nubla...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/YYBZa5Te0jo6Nd...</td>\n",
       "      <td>https://g1.globo.com/mg/triangulo-mineiro/noti...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:28:46 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FOTOS: Torcida em São Luís vibra com a vitória...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/LpmDUNtgjmKI1s...</td>\n",
       "      <td>https://g1.globo.com/ma/maranhao/noticia/2022/...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:28:37 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Black Friday: mesa posta para o Natal, gastand...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/XQ9uw0PeSXOhVS...</td>\n",
       "      <td>https://g1.globo.com/ba/bahia/especial-publici...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:28:31 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alerta de chuvas intensas é emitido para 54 ci...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/1KPAFo0uDd9CB-...</td>\n",
       "      <td>https://g1.globo.com/al/alagoas/noticia/2022/1...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:27:58 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Fora do agito da Fan Fest e da Vila Madalena, ...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/_4LyTqoKlhsoh9...</td>\n",
       "      <td>https://g1.globo.com/sp/sao-paulo/noticia/2022...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:27:43 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Apesar da chuva forte, torcedores de Mogi movi...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/yElbEhGKkBkBMh...</td>\n",
       "      <td>https://g1.globo.com/sp/mogi-das-cruzes-suzano...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:26:42 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vídeo de amigos bebendo em bar de BH em meio à...</td>\n",
       "      <td>Os dois estavam torcendo contra a Argentina em...</td>\n",
       "      <td>https://g1.globo.com/mg/minas-gerais/noticia/2...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:25:31 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mulher é morta a facadas durante briga no Lito...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/6AZmNX_qk88kRh...</td>\n",
       "      <td>https://g1.globo.com/pb/paraiba/noticia/2022/1...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:24:42 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Copa do Mundo: Eduardo Bolsonaro aparece no es...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/ZfWqPoYRkWaExH...</td>\n",
       "      <td>https://g1.globo.com/politica/noticia/2022/11/...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:24:30 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Idoso fica ferido após muro desabar sobre ele ...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/yzAKhBtLX28JyG...</td>\n",
       "      <td>https://g1.globo.com/mg/grande-minas/noticia/2...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:23:12 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Família que sofreu queimaduras durante incêndi...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/1N7qjUPpa29Wwu...</td>\n",
       "      <td>https://g1.globo.com/ac/acre/noticia/2022/11/2...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:22:37 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tensão e alívio com gol no fim marcam torcida ...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/ZhPCnTVJ3dJmjR...</td>\n",
       "      <td>https://g1.globo.com/sc/santa-catarina/noticia...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:21:49 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Polícia investiga homem que agrediu músico neg...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/A5VO1ymOBB_3ex...</td>\n",
       "      <td>https://g1.globo.com/pr/parana/noticia/2022/11...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:20:47 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ex-deputado e ex-ministro José Mucio está no g...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/Ql9UEacfanxlPL...</td>\n",
       "      <td>https://g1.globo.com/politica/blog/valdo-cruz/...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:20:45 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Van escolar desgovernada derruba muros de 2 ca...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/vesgK35zGD2QRG...</td>\n",
       "      <td>https://g1.globo.com/sp/sao-carlos-regiao/noti...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:20:32 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Motociclista de 24 anos morre após bater na tr...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/iJoA8Ni4EjbmX2...</td>\n",
       "      <td>https://g1.globo.com/pr/campos-gerais-sul/noti...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:18:43 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hospital Mestre Vitalino abre processo seletiv...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/7aKtMRMSf9D83Y...</td>\n",
       "      <td>https://g1.globo.com/pe/caruaru-regiao/noticia...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:18:05 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Torcedores da Baixada Santista comemoram vitór...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/XKoYnR_Xpe4DXO...</td>\n",
       "      <td>https://g1.globo.com/sp/santos-regiao/noticia/...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:14:08 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Estudante denuncia à polícia que 31 pessoas fo...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/4KsZpgKHIThfRw...</td>\n",
       "      <td>https://g1.globo.com/pb/paraiba/noticia/2022/1...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:10:32 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TCE nega pedido feito por equipe de Raquel Lyr...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/3JFSE9beHSIWL2...</td>\n",
       "      <td>https://g1.globo.com/pe/pernambuco/noticia/202...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:10:08 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>'Estação do Samba' leva música e diversão a Pa...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/3LxSaZM4n0eyzh...</td>\n",
       "      <td>https://g1.globo.com/rj/sul-do-rio-costa-verde...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:07:21 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Tubarão de 2 metros é capturado em praia de Sa...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/jBzmsPvENJ9KPC...</td>\n",
       "      <td>https://g1.globo.com/pa/para/noticia/2022/11/2...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:07:02 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Saiba onde vacinar crianças de 6 meses a 2 ano...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/I3RydsuxhVe653...</td>\n",
       "      <td>https://g1.globo.com/al/alagoas/noticia/2022/1...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:05:57 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Novembro Azul: Avaré oferece atendimentos notu...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/CkaIXz8ubC9p6Z...</td>\n",
       "      <td>https://g1.globo.com/sp/itapetininga-regiao/no...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:04:41 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Campanha de Vacinação Antirrábica realiza repe...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/8tbv6rn3c5wQBF...</td>\n",
       "      <td>https://g1.globo.com/se/sergipe/noticia/2022/1...</td>\n",
       "      <td>Mon, 28 Nov 2022 18:01:25 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>FOTOS: Deslizamento de rochas provoca interdiç...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/LVbT1nLs4gPsR0...</td>\n",
       "      <td>https://g1.globo.com/sc/santa-catarina/noticia...</td>\n",
       "      <td>Mon, 28 Nov 2022 17:57:35 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Governador da BA diz que vai aumentar nº de le...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/r-M91QPUoXA2Lr...</td>\n",
       "      <td>https://g1.globo.com/ba/bahia/noticia/2022/11/...</td>\n",
       "      <td>Mon, 28 Nov 2022 17:56:39 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Natal de Ibaté tem decoração, shows e presépio...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/wTN2tngGaAHhSZ...</td>\n",
       "      <td>https://g1.globo.com/sp/sao-carlos-regiao/noti...</td>\n",
       "      <td>Mon, 28 Nov 2022 17:50:18 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>De plantão, equipes do Corpo de Bombeiros de A...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/rFgAknHDsYPqzB...</td>\n",
       "      <td>https://g1.globo.com/al/alagoas/noticia/2022/1...</td>\n",
       "      <td>Mon, 28 Nov 2022 17:49:44 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Avô obriga neta de 10 anos a beber óleo de mot...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/VerPPODdGbf06l...</td>\n",
       "      <td>https://g1.globo.com/ms/mato-grosso-do-sul/not...</td>\n",
       "      <td>Mon, 28 Nov 2022 17:49:34 -0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TITLE  \\\n",
       "0   Perfil da PM em SC curte posts antidemocrático...   \n",
       "1   Ponte que liga Toca da Onça a Rio Bonito é rec...   \n",
       "2   Menina denuncia estupro à professora e ex-padr...   \n",
       "3   Treinador é preso no meio de partida de handeb...   \n",
       "4   Presidente da Associação de Catadoras e Catado...   \n",
       "5        VÍDEOS: AB1 de segunda-feira, 28 de novembro   \n",
       "6   Homem matou ex com um tiro na cabeça em frente...   \n",
       "7   Mulher leva tiro na cabeça enquanto assistia j...   \n",
       "8         Cresol constitui cooperativa no Mato Grosso   \n",
       "9   Espetáculo 'Cabaré Chinelo' encerra temporada ...   \n",
       "10  Novembro se encerra com céu parcialmente nubla...   \n",
       "11  FOTOS: Torcida em São Luís vibra com a vitória...   \n",
       "12  Black Friday: mesa posta para o Natal, gastand...   \n",
       "13  Alerta de chuvas intensas é emitido para 54 ci...   \n",
       "14  Fora do agito da Fan Fest e da Vila Madalena, ...   \n",
       "15  Apesar da chuva forte, torcedores de Mogi movi...   \n",
       "16  Vídeo de amigos bebendo em bar de BH em meio à...   \n",
       "17  Mulher é morta a facadas durante briga no Lito...   \n",
       "18  Copa do Mundo: Eduardo Bolsonaro aparece no es...   \n",
       "19  Idoso fica ferido após muro desabar sobre ele ...   \n",
       "20  Família que sofreu queimaduras durante incêndi...   \n",
       "21  Tensão e alívio com gol no fim marcam torcida ...   \n",
       "22  Polícia investiga homem que agrediu músico neg...   \n",
       "23  Ex-deputado e ex-ministro José Mucio está no g...   \n",
       "24  Van escolar desgovernada derruba muros de 2 ca...   \n",
       "25  Motociclista de 24 anos morre após bater na tr...   \n",
       "26  Hospital Mestre Vitalino abre processo seletiv...   \n",
       "27  Torcedores da Baixada Santista comemoram vitór...   \n",
       "28  Estudante denuncia à polícia que 31 pessoas fo...   \n",
       "29  TCE nega pedido feito por equipe de Raquel Lyr...   \n",
       "30  'Estação do Samba' leva música e diversão a Pa...   \n",
       "31  Tubarão de 2 metros é capturado em praia de Sa...   \n",
       "32  Saiba onde vacinar crianças de 6 meses a 2 ano...   \n",
       "33  Novembro Azul: Avaré oferece atendimentos notu...   \n",
       "34  Campanha de Vacinação Antirrábica realiza repe...   \n",
       "35  FOTOS: Deslizamento de rochas provoca interdiç...   \n",
       "36  Governador da BA diz que vai aumentar nº de le...   \n",
       "37  Natal de Ibaté tem decoração, shows e presépio...   \n",
       "38  De plantão, equipes do Corpo de Bombeiros de A...   \n",
       "39  Avô obriga neta de 10 anos a beber óleo de mot...   \n",
       "\n",
       "                                              CONTENT  \\\n",
       "0   <img src=\"https://s2.glbimg.com/hHaPhjo7AiNLn-...   \n",
       "1   <img src=\"https://s2.glbimg.com/iA1ARsUvBzuFOH...   \n",
       "2   <img src=\"https://s2.glbimg.com/DsJJ0ftZ_UF0g9...   \n",
       "3   <img src=\"https://s2.glbimg.com/lGTqe75_EueDyo...   \n",
       "4   <img src=\"https://s2.glbimg.com/MOruxIfu5xe5ku...   \n",
       "5   <img src=\"https://s2.glbimg.com/QHEuQoE9N98BI0...   \n",
       "6   <img src=\"https://s2.glbimg.com/VYG-_GYfr3uh6U...   \n",
       "7   <img src=\"https://s2.glbimg.com/Af4Z8E2f5SH5N5...   \n",
       "8   <img src=\"https://s2.glbimg.com/kwDswG7_VnwyUz...   \n",
       "9   <img src=\"https://s2.glbimg.com/am3JENH4WLtILA...   \n",
       "10  <img src=\"https://s2.glbimg.com/YYBZa5Te0jo6Nd...   \n",
       "11  <img src=\"https://s2.glbimg.com/LpmDUNtgjmKI1s...   \n",
       "12  <img src=\"https://s2.glbimg.com/XQ9uw0PeSXOhVS...   \n",
       "13  <img src=\"https://s2.glbimg.com/1KPAFo0uDd9CB-...   \n",
       "14  <img src=\"https://s2.glbimg.com/_4LyTqoKlhsoh9...   \n",
       "15  <img src=\"https://s2.glbimg.com/yElbEhGKkBkBMh...   \n",
       "16  Os dois estavam torcendo contra a Argentina em...   \n",
       "17  <img src=\"https://s2.glbimg.com/6AZmNX_qk88kRh...   \n",
       "18  <img src=\"https://s2.glbimg.com/ZfWqPoYRkWaExH...   \n",
       "19  <img src=\"https://s2.glbimg.com/yzAKhBtLX28JyG...   \n",
       "20  <img src=\"https://s2.glbimg.com/1N7qjUPpa29Wwu...   \n",
       "21  <img src=\"https://s2.glbimg.com/ZhPCnTVJ3dJmjR...   \n",
       "22  <img src=\"https://s2.glbimg.com/A5VO1ymOBB_3ex...   \n",
       "23  <img src=\"https://s2.glbimg.com/Ql9UEacfanxlPL...   \n",
       "24  <img src=\"https://s2.glbimg.com/vesgK35zGD2QRG...   \n",
       "25  <img src=\"https://s2.glbimg.com/iJoA8Ni4EjbmX2...   \n",
       "26  <img src=\"https://s2.glbimg.com/7aKtMRMSf9D83Y...   \n",
       "27  <img src=\"https://s2.glbimg.com/XKoYnR_Xpe4DXO...   \n",
       "28  <img src=\"https://s2.glbimg.com/4KsZpgKHIThfRw...   \n",
       "29  <img src=\"https://s2.glbimg.com/3JFSE9beHSIWL2...   \n",
       "30  <img src=\"https://s2.glbimg.com/3LxSaZM4n0eyzh...   \n",
       "31  <img src=\"https://s2.glbimg.com/jBzmsPvENJ9KPC...   \n",
       "32  <img src=\"https://s2.glbimg.com/I3RydsuxhVe653...   \n",
       "33  <img src=\"https://s2.glbimg.com/CkaIXz8ubC9p6Z...   \n",
       "34  <img src=\"https://s2.glbimg.com/8tbv6rn3c5wQBF...   \n",
       "35  <img src=\"https://s2.glbimg.com/LVbT1nLs4gPsR0...   \n",
       "36  <img src=\"https://s2.glbimg.com/r-M91QPUoXA2Lr...   \n",
       "37  <img src=\"https://s2.glbimg.com/wTN2tngGaAHhSZ...   \n",
       "38  <img src=\"https://s2.glbimg.com/rFgAknHDsYPqzB...   \n",
       "39  <img src=\"https://s2.glbimg.com/VerPPODdGbf06l...   \n",
       "\n",
       "                                                 LINK  \\\n",
       "0   https://g1.globo.com/sc/santa-catarina/noticia...   \n",
       "1   https://g1.globo.com/rj/regiao-serrana/noticia...   \n",
       "2   https://g1.globo.com/go/goias/noticia/2022/11/...   \n",
       "3   https://g1.globo.com/sc/santa-catarina/noticia...   \n",
       "4   https://g1.globo.com/se/sergipe/noticia/2022/1...   \n",
       "5   https://g1.globo.com/pe/caruaru-regiao/edicao/...   \n",
       "6   https://g1.globo.com/rs/rio-grande-do-sul/noti...   \n",
       "7   https://g1.globo.com/to/tocantins/noticia/2022...   \n",
       "8   https://g1.globo.com/pr/parana/especial-public...   \n",
       "9   https://g1.globo.com/am/amazonas/noticia/2022/...   \n",
       "10  https://g1.globo.com/mg/triangulo-mineiro/noti...   \n",
       "11  https://g1.globo.com/ma/maranhao/noticia/2022/...   \n",
       "12  https://g1.globo.com/ba/bahia/especial-publici...   \n",
       "13  https://g1.globo.com/al/alagoas/noticia/2022/1...   \n",
       "14  https://g1.globo.com/sp/sao-paulo/noticia/2022...   \n",
       "15  https://g1.globo.com/sp/mogi-das-cruzes-suzano...   \n",
       "16  https://g1.globo.com/mg/minas-gerais/noticia/2...   \n",
       "17  https://g1.globo.com/pb/paraiba/noticia/2022/1...   \n",
       "18  https://g1.globo.com/politica/noticia/2022/11/...   \n",
       "19  https://g1.globo.com/mg/grande-minas/noticia/2...   \n",
       "20  https://g1.globo.com/ac/acre/noticia/2022/11/2...   \n",
       "21  https://g1.globo.com/sc/santa-catarina/noticia...   \n",
       "22  https://g1.globo.com/pr/parana/noticia/2022/11...   \n",
       "23  https://g1.globo.com/politica/blog/valdo-cruz/...   \n",
       "24  https://g1.globo.com/sp/sao-carlos-regiao/noti...   \n",
       "25  https://g1.globo.com/pr/campos-gerais-sul/noti...   \n",
       "26  https://g1.globo.com/pe/caruaru-regiao/noticia...   \n",
       "27  https://g1.globo.com/sp/santos-regiao/noticia/...   \n",
       "28  https://g1.globo.com/pb/paraiba/noticia/2022/1...   \n",
       "29  https://g1.globo.com/pe/pernambuco/noticia/202...   \n",
       "30  https://g1.globo.com/rj/sul-do-rio-costa-verde...   \n",
       "31  https://g1.globo.com/pa/para/noticia/2022/11/2...   \n",
       "32  https://g1.globo.com/al/alagoas/noticia/2022/1...   \n",
       "33  https://g1.globo.com/sp/itapetininga-regiao/no...   \n",
       "34  https://g1.globo.com/se/sergipe/noticia/2022/1...   \n",
       "35  https://g1.globo.com/sc/santa-catarina/noticia...   \n",
       "36  https://g1.globo.com/ba/bahia/noticia/2022/11/...   \n",
       "37  https://g1.globo.com/sp/sao-carlos-regiao/noti...   \n",
       "38  https://g1.globo.com/al/alagoas/noticia/2022/1...   \n",
       "39  https://g1.globo.com/ms/mato-grosso-do-sul/not...   \n",
       "\n",
       "                     TIME_PUBLISHED  \n",
       "0   Mon, 28 Nov 2022 18:39:29 -0000  \n",
       "1   Mon, 28 Nov 2022 18:39:25 -0000  \n",
       "2   Mon, 28 Nov 2022 18:38:07 -0000  \n",
       "3   Mon, 28 Nov 2022 18:36:53 -0000  \n",
       "4   Mon, 28 Nov 2022 18:33:29 -0000  \n",
       "5   Mon, 28 Nov 2022 18:31:45 -0000  \n",
       "6   Mon, 28 Nov 2022 18:31:31 -0000  \n",
       "7   Mon, 28 Nov 2022 18:31:08 -0000  \n",
       "8   Mon, 28 Nov 2022 18:30:12 -0000  \n",
       "9   Mon, 28 Nov 2022 18:30:08 -0000  \n",
       "10  Mon, 28 Nov 2022 18:28:46 -0000  \n",
       "11  Mon, 28 Nov 2022 18:28:37 -0000  \n",
       "12  Mon, 28 Nov 2022 18:28:31 -0000  \n",
       "13  Mon, 28 Nov 2022 18:27:58 -0000  \n",
       "14  Mon, 28 Nov 2022 18:27:43 -0000  \n",
       "15  Mon, 28 Nov 2022 18:26:42 -0000  \n",
       "16  Mon, 28 Nov 2022 18:25:31 -0000  \n",
       "17  Mon, 28 Nov 2022 18:24:42 -0000  \n",
       "18  Mon, 28 Nov 2022 18:24:30 -0000  \n",
       "19  Mon, 28 Nov 2022 18:23:12 -0000  \n",
       "20  Mon, 28 Nov 2022 18:22:37 -0000  \n",
       "21  Mon, 28 Nov 2022 18:21:49 -0000  \n",
       "22  Mon, 28 Nov 2022 18:20:47 -0000  \n",
       "23  Mon, 28 Nov 2022 18:20:45 -0000  \n",
       "24  Mon, 28 Nov 2022 18:20:32 -0000  \n",
       "25  Mon, 28 Nov 2022 18:18:43 -0000  \n",
       "26  Mon, 28 Nov 2022 18:18:05 -0000  \n",
       "27  Mon, 28 Nov 2022 18:14:08 -0000  \n",
       "28  Mon, 28 Nov 2022 18:10:32 -0000  \n",
       "29  Mon, 28 Nov 2022 18:10:08 -0000  \n",
       "30  Mon, 28 Nov 2022 18:07:21 -0000  \n",
       "31  Mon, 28 Nov 2022 18:07:02 -0000  \n",
       "32  Mon, 28 Nov 2022 18:05:57 -0000  \n",
       "33  Mon, 28 Nov 2022 18:04:41 -0000  \n",
       "34  Mon, 28 Nov 2022 18:01:25 -0000  \n",
       "35  Mon, 28 Nov 2022 17:57:35 -0000  \n",
       "36  Mon, 28 Nov 2022 17:56:39 -0000  \n",
       "37  Mon, 28 Nov 2022 17:50:18 -0000  \n",
       "38  Mon, 28 Nov 2022 17:49:44 -0000  \n",
       "39  Mon, 28 Nov 2022 17:49:34 -0000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feedparser\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://g1.globo.com/rss/g1/'\n",
    "\n",
    "blog_feed = feedparser.parse(url)\n",
    "\n",
    "posts = blog_feed.entries  \n",
    "post_list = []\n",
    "\n",
    "for post in posts:\n",
    "    post_dict = dict()\n",
    "\n",
    "    post_dict[\"TITLE\"] = post.title\n",
    "    post_dict[\"CONTENT\"] = post.summary\n",
    "    post_dict[\"LINK\"] = post.link\n",
    "    post_dict[\"TIME_PUBLISHED\"] = post.published\n",
    "    # post_dict[\"TAGS\"] = [tag.term for tag in post.tags]\n",
    "\n",
    "    post_list.append(post_dict)\n",
    "df_post = pd.DataFrame(post_list)\n",
    "df_post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaad118-19a8-45fd-a880-070708dff7bf",
   "metadata": {},
   "source": [
    "### Create your first metaflow workflow\n",
    "\n",
    "Now that we downloaded the data we can use to create new features. Let's create a workflow to download feeds from differente providers. No we are going to user [Neflix Open Source metaflow Workflow package](https://metaflow.org/) to make the job easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c745d2-c5b8-471c-859b-6c0fa9a63b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following packages are already present in the pyproject.toml and will be skipped:\n",
      "\n",
      "  • \u001b[36mmetaflow\u001b[39m\n",
      "\n",
      "If you want to update it to the latest compatible version, you can use `poetry update package`.\n",
      "If you prefer to upgrade it to the latest available version, you can use `poetry add package@latest`.\n",
      "\n",
      "Nothing to add.\n"
     ]
    }
   ],
   "source": [
    "!poetry add metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5367033d-f3c4-4204-b79f-b13fc4507f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring colorama: markers 'sys_platform == \"win32\" and python_full_version == \"3.10.6\"' don't match your environment\n",
      "Requirement already satisfied: astroid==2.12.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.12.13)\n",
      "Requirement already satisfied: boto3==1.26.17 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.26.17)\n",
      "Requirement already satisfied: botocore==1.29.17 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.29.17)\n",
      "Requirement already satisfied: certifi==2022.9.24 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer==2.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.1.1)\n",
      "Requirement already satisfied: dill==0.3.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (0.3.6)\n",
      "Requirement already satisfied: feedparser==6.0.10 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (6.0.10)\n",
      "Requirement already satisfied: idna==3.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (3.4)\n",
      "Requirement already satisfied: isort==5.10.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (5.10.1)\n",
      "Requirement already satisfied: jmespath==1.0.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 31)) (1.0.1)\n",
      "Requirement already satisfied: lazy-object-proxy==1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 34)) (1.8.0)\n",
      "Requirement already satisfied: mccabe==0.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 54)) (0.7.0)\n",
      "Requirement already satisfied: metaflow==2.7.14 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 57)) (2.7.14)\n",
      "Requirement already satisfied: numpy==1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 60)) (1.23.5)\n",
      "Requirement already satisfied: pandas==1.5.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 89)) (1.5.2)\n",
      "Requirement already satisfied: platformdirs==2.5.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 117)) (2.5.4)\n",
      "Requirement already satisfied: pylint==2.15.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 120)) (2.15.6)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 123)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 126)) (2022.6)\n",
      "Requirement already satisfied: requests==2.28.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 129)) (2.28.1)\n",
      "Requirement already satisfied: s3transfer==0.6.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 132)) (0.6.0)\n",
      "Requirement already satisfied: sgmllib3k==1.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 135)) (1.0.0)\n",
      "Requirement already satisfied: six==1.16.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 137)) (1.16.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 140)) (2.0.1)\n",
      "Requirement already satisfied: tomlkit==0.11.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 143)) (0.11.6)\n",
      "Requirement already satisfied: urllib3==1.26.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 146)) (1.26.13)\n",
      "Requirement already satisfied: wrapt==1.14.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 149)) (1.14.1)\n"
     ]
    }
   ],
   "source": [
    "!poetry export -f requirements.txt --output requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7cbbdc33-991a-4916-a148-f065e0bda167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/data/feeds_flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/data/feeds_flow.py\n",
    "\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "\n",
    "from metaflow import FlowSpec, step\n",
    "\n",
    "class FeedsFlow(FlowSpec):\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.feeds_url = [\n",
    "            'https://feeds.folha.uol.com.br/emcimadahora/rss091.xml',\n",
    "            'https://g1.globo.com/rss/g1/',\n",
    "            'https://g1.globo.com/rss/g1/brasil'\n",
    "        ]\n",
    "        self.next(self.fetch_feed_data, foreach='feeds_url')\n",
    "\n",
    "    @step\n",
    "    def fetch_feed_data(self):\n",
    "        \n",
    "        print(f\"Downloading from url {self.input}\")\n",
    "        blog_feed = feedparser.parse(self.input)\n",
    "\n",
    "        posts = blog_feed.entries  \n",
    "        post_list = []\n",
    "\n",
    "        for post in posts:\n",
    "            post_dict = dict()\n",
    "\n",
    "            post_dict[\"TITLE\"] = post.title\n",
    "            post_dict[\"CONTENT\"] = post.summary\n",
    "            post_dict[\"LINK\"] = post.link\n",
    "            post_dict[\"TIME_PUBLISHED\"] = post.published\n",
    "            # post_dict[\"TAGS\"] = [tag.term for tag in post.tags]\n",
    "\n",
    "            post_list.append(post_dict)\n",
    "        self.posts = pd.DataFrame(post_list)        \n",
    "        self.next(self.feeds_aggregate)\n",
    "\n",
    "    @step\n",
    "    def feeds_aggregate(self, inputs):\n",
    "        self.results = pd.concat([input.posts for input in inputs])\n",
    "        self.next(self.end)\n",
    "              \n",
    "    @step\n",
    "    def end(self):\n",
    "        print('Workflow finished!')\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    FeedsFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55d7c633-53cb-4cda-b4ed-a9a991ebe928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.14\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mFeedsFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:jovyan\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[22mCreating local datastore in current directory (/home/jovyan/.metaflow)\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\n",
      "\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\n",
      "Step \u001b[0m\u001b[31m\u001b[1mstart\u001b[0m\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m    ?\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m    \u001b[0m\u001b[35m\u001b[22m=>\u001b[0m\u001b[22m \u001b[0m\u001b[35m\u001b[22mfetch_feed_data\u001b[0m\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\n",
      "Step \u001b[0m\u001b[31m\u001b[1mfetch_feed_data\u001b[0m\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m    ?\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m    \u001b[0m\u001b[35m\u001b[22m=>\u001b[0m\u001b[22m \u001b[0m\u001b[35m\u001b[22mfeeds_aggregate\u001b[0m\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\n",
      "Step \u001b[0m\u001b[31m\u001b[1mfeeds_aggregate\u001b[0m\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m    ?\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m    \u001b[0m\u001b[35m\u001b[22m=>\u001b[0m\u001b[22m \u001b[0m\u001b[35m\u001b[22mend\u001b[0m\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\n",
      "Step \u001b[0m\u001b[31m\u001b[1mend\u001b[0m\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m    ?\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python src/data/feeds_flow.py show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32e8fd93-3777-4752-8b54-3435687aa49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.14\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mFeedsFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:jovyan\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:55.608 \u001b[0m\u001b[1mWorkflow starting (run-id 1669405615532166):\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:55.636 \u001b[0m\u001b[32m[1669405615532166/start/1 (pid 11613)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:56.291 \u001b[0m\u001b[32m[1669405615532166/start/1 (pid 11613)] \u001b[0m\u001b[1mForeach yields 3 child steps.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:56.291 \u001b[0m\u001b[32m[1669405615532166/start/1 (pid 11613)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:56.328 \u001b[0m\u001b[32m[1669405615532166/fetch_feed_data/2 (pid 11617)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:56.347 \u001b[0m\u001b[32m[1669405615532166/fetch_feed_data/3 (pid 11618)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:56.370 \u001b[0m\u001b[32m[1669405615532166/fetch_feed_data/4 (pid 11619)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:57.059 \u001b[0m\u001b[32m[1669405615532166/fetch_feed_data/2 (pid 11617)] \u001b[0m\u001b[22mDownloading from url https://feeds.folha.uol.com.br/emcimadahora/rss091.xml\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:57.210 \u001b[0m\u001b[32m[1669405615532166/fetch_feed_data/4 (pid 11619)] \u001b[0m\u001b[22mDownloading from url https://g1.globo.com/rss/g1/brasil\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:57.289 \u001b[0m\u001b[32m[1669405615532166/fetch_feed_data/3 (pid 11618)] \u001b[0m\u001b[22mDownloading from url https://g1.globo.com/rss/g1/\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:57.435 \u001b[0m\u001b[32m[1669405615532166/fetch_feed_data/2 (pid 11617)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:57.606 \u001b[0m\u001b[32m[1669405615532166/fetch_feed_data/3 (pid 11618)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:57.787 \u001b[0m\u001b[32m[1669405615532166/fetch_feed_data/4 (pid 11619)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:57.820 \u001b[0m\u001b[32m[1669405615532166/feeds_aggregate/5 (pid 11629)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:58.518 \u001b[0m\u001b[32m[1669405615532166/feeds_aggregate/5 (pid 11629)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:58.554 \u001b[0m\u001b[32m[1669405615532166/end/6 (pid 11633)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:59.035 \u001b[0m\u001b[32m[1669405615532166/end/6 (pid 11633)] \u001b[0m\u001b[22mWorkflow finished!\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:59.184 \u001b[0m\u001b[32m[1669405615532166/end/6 (pid 11633)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:46:59.190 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python src/data/feeds_flow.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c6d82c-44fa-43de-a806-1a2d16622e81",
   "metadata": {},
   "source": [
    "### Investigating results\n",
    "\n",
    "Metaflow package has a builtin experiment versioning system. Let's analyze the worflow and its executions so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3ba5400-b375-4c45-99b3-a4c67f272f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run('FeedsFlow/1669405615532166')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metaflow import Flow\n",
    "fl = Flow('FeedsFlow')\n",
    "runs_list = list(fl)\n",
    "runs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec822e6f-0db5-45fb-9526-2e89aa82cef7",
   "metadata": {},
   "source": [
    "It is possible to see all valid runs, that by now are running locally. Let's analyze the results from last run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f576c8b-d72b-4a71-bdce-3d03aa373cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Run\n",
    "r = fl.latest_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb380e2-cf45-4021-ac71-5c259a04705d",
   "metadata": {},
   "source": [
    "Acessing the `data` attribute for the run it is possible to see the final result consolidated by the run. Let's analyze it and compare to the manually generated data created before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "998c7b3e-b6b0-4009-81d2-d64b0d6b004e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>LINK</th>\n",
       "      <th>TIME_PUBLISHED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maldição da Copa estraga até os melhores bares</td>\n",
       "      <td>Na Copa do Mundo, como em qualquer outra ocasi...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:32:00 -0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fifa divulga dados de público maiores que capa...</td>\n",
       "      <td>Deu no álbum da &lt;a href=\"https://www1.folha.uo...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:28:00 -0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Economia libera R$ 37,4 milhões para PF retoma...</td>\n",
       "      <td>O Ministério da Economia editou uma portaria p...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:23:00 -0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ingleses voltam a protestar contra o racismo a...</td>\n",
       "      <td>Da mesma forma que fizeram na estreia da &lt;a hr...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:15:00 -0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arqueólogos solucionam mistério e encontram mu...</td>\n",
       "      <td>Uma equipe de &lt;a href=\"https://www1.folha.uol....</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:11:00 -0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Procon suspende atendimentos nesta terça e qua...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/3pgG9TP2ryZosq...</td>\n",
       "      <td>https://g1.globo.com/mg/triangulo-mineiro/noti...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:33:44 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Homem persegue esposa com facão após vítima vo...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/3bNJ3sUSiloSnI...</td>\n",
       "      <td>https://g1.globo.com/ro/rondonia/noticia/2018/...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:30:17 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Quase dois anos após matar grávida e roubar be...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/scebsn6NM18wLX...</td>\n",
       "      <td>https://g1.globo.com/mg/triangulo-mineiro/noti...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:21:41 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Homem é preso pela Polícia Civil por suspeita ...</td>\n",
       "      <td>Segundo delegado, foram necessárias três seman...</td>\n",
       "      <td>https://g1.globo.com/mg/zona-da-mata/noticia/2...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:06:03 -0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10 mil pessoas foram indenizadas por invalidez...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/L4fE7nlg-zifJe...</td>\n",
       "      <td>https://g1.globo.com/ce/ceara/noticia/2018/07/...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:04:44 -0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TITLE  \\\n",
       "0      Maldição da Copa estraga até os melhores bares   \n",
       "1   Fifa divulga dados de público maiores que capa...   \n",
       "2   Economia libera R$ 37,4 milhões para PF retoma...   \n",
       "3   Ingleses voltam a protestar contra o racismo a...   \n",
       "4   Arqueólogos solucionam mistério e encontram mu...   \n",
       "..                                                ...   \n",
       "35  Procon suspende atendimentos nesta terça e qua...   \n",
       "36  Homem persegue esposa com facão após vítima vo...   \n",
       "37  Quase dois anos após matar grávida e roubar be...   \n",
       "38  Homem é preso pela Polícia Civil por suspeita ...   \n",
       "39  10 mil pessoas foram indenizadas por invalidez...   \n",
       "\n",
       "                                              CONTENT  \\\n",
       "0   Na Copa do Mundo, como em qualquer outra ocasi...   \n",
       "1   Deu no álbum da <a href=\"https://www1.folha.uo...   \n",
       "2   O Ministério da Economia editou uma portaria p...   \n",
       "3   Da mesma forma que fizeram na estreia da <a hr...   \n",
       "4   Uma equipe de <a href=\"https://www1.folha.uol....   \n",
       "..                                                ...   \n",
       "35  <img src=\"https://s2.glbimg.com/3pgG9TP2ryZosq...   \n",
       "36  <img src=\"https://s2.glbimg.com/3bNJ3sUSiloSnI...   \n",
       "37  <img src=\"https://s2.glbimg.com/scebsn6NM18wLX...   \n",
       "38  Segundo delegado, foram necessárias três seman...   \n",
       "39  <img src=\"https://s2.glbimg.com/L4fE7nlg-zifJe...   \n",
       "\n",
       "                                                 LINK  \\\n",
       "0   https://redir.folha.com.br/redir/online/emcima...   \n",
       "1   https://redir.folha.com.br/redir/online/emcima...   \n",
       "2   https://redir.folha.com.br/redir/online/emcima...   \n",
       "3   https://redir.folha.com.br/redir/online/emcima...   \n",
       "4   https://redir.folha.com.br/redir/online/emcima...   \n",
       "..                                                ...   \n",
       "35  https://g1.globo.com/mg/triangulo-mineiro/noti...   \n",
       "36  https://g1.globo.com/ro/rondonia/noticia/2018/...   \n",
       "37  https://g1.globo.com/mg/triangulo-mineiro/noti...   \n",
       "38  https://g1.globo.com/mg/zona-da-mata/noticia/2...   \n",
       "39  https://g1.globo.com/ce/ceara/noticia/2018/07/...   \n",
       "\n",
       "                     TIME_PUBLISHED  \n",
       "0        25 Nov 2022 16:32:00 -0300  \n",
       "1        25 Nov 2022 16:28:00 -0300  \n",
       "2        25 Nov 2022 16:23:00 -0300  \n",
       "3        25 Nov 2022 16:15:00 -0300  \n",
       "4        25 Nov 2022 16:11:00 -0300  \n",
       "..                              ...  \n",
       "35  Mon, 23 Jul 2018 15:33:44 -0000  \n",
       "36  Mon, 23 Jul 2018 15:30:17 -0000  \n",
       "37  Mon, 23 Jul 2018 15:21:41 -0000  \n",
       "38  Mon, 23 Jul 2018 15:06:03 -0000  \n",
       "39  Mon, 23 Jul 2018 15:04:44 -0000  \n",
       "\n",
       "[180 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r = r.data.results\n",
    "df_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38f0f5-e19c-4caf-a6f5-ad55531151db",
   "metadata": {},
   "source": [
    "## Feature generation\n",
    "\n",
    "Now that we have been able to add news from other sources, let's run a simple feature generation process. As the goal is to tokenize the results, let's add a new step to the workflow creating a tokenized version of the content. The final goal is to apply an LDA transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78e42edc-5fc5-4544-bc61-3f0fb5f3d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version \u001b[39;1m^3.7\u001b[39;22m for \u001b[36mnltk\u001b[39m\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[39m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(0.6s)\u001b[39;22m\n",
      "\n",
      "\u001b[34mWriting lock file\u001b[39m\n",
      "\n",
      "No dependencies to install or update\n"
     ]
    }
   ],
   "source": [
    "!poetry add nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b371b61-ad3d-4f98-b4cf-25d6fefe15ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring colorama: markers 'sys_platform == \"win32\" and python_full_version == \"3.10.6\" or platform_system == \"Windows\" and python_full_version == \"3.10.6\"' don't match your environment\n",
      "Requirement already satisfied: astroid==2.12.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.12.13)\n",
      "Requirement already satisfied: boto3==1.26.17 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.26.17)\n",
      "Requirement already satisfied: botocore==1.29.17 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.29.17)\n",
      "Requirement already satisfied: certifi==2022.9.24 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer==2.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.1.1)\n",
      "Collecting click==8.1.3\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: dill==0.3.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (0.3.6)\n",
      "Requirement already satisfied: feedparser==6.0.10 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (6.0.10)\n",
      "Requirement already satisfied: idna==3.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (3.4)\n",
      "Requirement already satisfied: isort==5.10.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 31)) (5.10.1)\n",
      "Requirement already satisfied: jmespath==1.0.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 34)) (1.0.1)\n",
      "Collecting joblib==1.2.0\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Requirement already satisfied: lazy-object-proxy==1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 40)) (1.8.0)\n",
      "Requirement already satisfied: mccabe==0.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 60)) (0.7.0)\n",
      "Requirement already satisfied: metaflow==2.7.14 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 63)) (2.7.14)\n",
      "Collecting nltk==3.7\n",
      "  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: numpy==1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 69)) (1.23.5)\n",
      "Requirement already satisfied: pandas==1.5.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 98)) (1.5.2)\n",
      "Requirement already satisfied: platformdirs==2.5.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 126)) (2.5.4)\n",
      "Requirement already satisfied: pylint==2.15.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 129)) (2.15.6)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 132)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 135)) (2022.6)\n",
      "Collecting regex==2022.10.31\n",
      "  Using cached regex-2022.10.31-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (769 kB)\n",
      "Requirement already satisfied: requests==2.28.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 227)) (2.28.1)\n",
      "Requirement already satisfied: s3transfer==0.6.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 230)) (0.6.0)\n",
      "Requirement already satisfied: sgmllib3k==1.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 233)) (1.0.0)\n",
      "Requirement already satisfied: six==1.16.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 235)) (1.16.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 238)) (2.0.1)\n",
      "Requirement already satisfied: tomlkit==0.11.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 241)) (0.11.6)\n",
      "Requirement already satisfied: tqdm==4.64.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 244)) (4.64.1)\n",
      "Requirement already satisfied: urllib3==1.26.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 247)) (1.26.13)\n",
      "Requirement already satisfied: wrapt==1.14.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 250)) (1.14.1)\n",
      "Installing collected packages: regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.3 joblib-1.2.0 nltk-3.7 regex-2022.10.31\n"
     ]
    }
   ],
   "source": [
    "!poetry export -f requirements.txt --output requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eac60e16-d498-41ea-9a9d-0b077de9e353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /home/jovyan/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a11ad7-1f6b-44c7-811f-78d753b202f2",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Our new workflow will have a preprocess step added to tokenize news texts. Let's bring back the old workflow and add new code to it. You can get the file we just generated by executing the load command in an empty cell:\n",
    "\n",
    "```\n",
    "%load src/data/feeds_flow.py\n",
    "```\n",
    "\n",
    "Then we will write the results back to the cell\n",
    "\n",
    "\n",
    "```\n",
    "%%writefile src/data/feeds_flow.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ffbf531-1c3c-4965-a15a-6c01904cee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/data/feeds_flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/data/feeds_flow.py\n",
    "# %load src/data/feeds_flow.py\n",
    "\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "import pendulum\n",
    "\n",
    "from metaflow import FlowSpec, step\n",
    "\n",
    "class FeedsFlow(FlowSpec):\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.feeds_url = [\n",
    "            'https://feeds.folha.uol.com.br/emcimadahora/rss091.xml',\n",
    "            'https://g1.globo.com/rss/g1/',\n",
    "            'https://g1.globo.com/rss/g1/brasil'\n",
    "        ]\n",
    "        self.next(self.fetch_feed_data, foreach='feeds_url')\n",
    "\n",
    "    @step\n",
    "    def fetch_feed_data(self):\n",
    "        \n",
    "        print(f\"Downloading from url {self.input}\")\n",
    "        blog_feed = feedparser.parse(self.input)\n",
    "\n",
    "        posts = blog_feed.entries  \n",
    "        post_list = []\n",
    "\n",
    "        for post in posts:\n",
    "            post_dict = dict()\n",
    "\n",
    "            post_dict[\"TITLE\"] = post.title\n",
    "            post_dict[\"CONTENT\"] = post.summary\n",
    "            post_dict[\"LINK\"] = post.link\n",
    "            post_dict[\"TIME_PUBLISHED\"] = post.published\n",
    "            # post_dict[\"TAGS\"] = [tag.term for tag in post.tags]\n",
    "\n",
    "            post_list.append(post_dict)\n",
    "\n",
    "        self.posts = pd.DataFrame(post_list)        \n",
    "        self.next(self.feeds_aggregate)\n",
    "\n",
    "    @step\n",
    "    def feeds_aggregate(self, inputs):\n",
    "        self.results = pd.concat([input.posts for input in inputs])\n",
    "        self.next(self.preprocess_pandas)\n",
    "              \n",
    "    @step\n",
    "    def preprocess_pandas(self):\n",
    "        stop = set(stopwords.words('portuguese') + list(string.punctuation))\n",
    "        stop.update(['http', 'pro', 'https', 't.', 'co'])\n",
    "\n",
    "        def preprocess(words):\n",
    "            # Remove HTML marks\n",
    "            words = re.sub('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', '', words)\n",
    "            tokens = word_tokenize(words)\n",
    "            tokens = [word for word in tokens if word not in stop]\n",
    "            tokens = [word for word in tokens if re.search(r'\\w+', word) and len(word) > 2]\n",
    "            return tokens\n",
    "    \n",
    "        self.results['token_set'] = self.results.apply(lambda row: preprocess(row.CONTENT.lower()), axis=1)\n",
    "        print(\"Tokenization finished!\")\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        print('Workflow finished!')\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    FeedsFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d14fa820-7b12-4370-97b1-8adb1161feec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.14\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mFeedsFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:jovyan\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:18.553 \u001b[0m\u001b[1mWorkflow starting (run-id 1669406058484905):\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:18.577 \u001b[0m\u001b[32m[1669406058484905/start/1 (pid 11988)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:19.284 \u001b[0m\u001b[32m[1669406058484905/start/1 (pid 11988)] \u001b[0m\u001b[1mForeach yields 3 child steps.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:19.284 \u001b[0m\u001b[32m[1669406058484905/start/1 (pid 11988)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:19.320 \u001b[0m\u001b[32m[1669406058484905/fetch_feed_data/2 (pid 11999)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:19.336 \u001b[0m\u001b[32m[1669406058484905/fetch_feed_data/3 (pid 12000)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:19.350 \u001b[0m\u001b[32m[1669406058484905/fetch_feed_data/4 (pid 12001)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:20.298 \u001b[0m\u001b[32m[1669406058484905/fetch_feed_data/3 (pid 12000)] \u001b[0m\u001b[22mDownloading from url https://g1.globo.com/rss/g1/\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:20.304 \u001b[0m\u001b[32m[1669406058484905/fetch_feed_data/2 (pid 11999)] \u001b[0m\u001b[22mDownloading from url https://feeds.folha.uol.com.br/emcimadahora/rss091.xml\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:20.305 \u001b[0m\u001b[32m[1669406058484905/fetch_feed_data/4 (pid 12001)] \u001b[0m\u001b[22mDownloading from url https://g1.globo.com/rss/g1/brasil\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:20.669 \u001b[0m\u001b[32m[1669406058484905/fetch_feed_data/3 (pid 12000)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:20.762 \u001b[0m\u001b[32m[1669406058484905/fetch_feed_data/4 (pid 12001)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:20.790 \u001b[0m\u001b[32m[1669406058484905/fetch_feed_data/2 (pid 11999)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:20.823 \u001b[0m\u001b[32m[1669406058484905/feeds_aggregate/5 (pid 12011)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:21.625 \u001b[0m\u001b[32m[1669406058484905/feeds_aggregate/5 (pid 12011)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:21.659 \u001b[0m\u001b[32m[1669406058484905/preprocess_pandas/6 (pid 12015)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:22.383 \u001b[0m\u001b[32m[1669406058484905/preprocess_pandas/6 (pid 12015)] \u001b[0m\u001b[22mTokenization finished!\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:22.579 \u001b[0m\u001b[32m[1669406058484905/preprocess_pandas/6 (pid 12015)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:22.610 \u001b[0m\u001b[32m[1669406058484905/end/7 (pid 12019)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:23.201 \u001b[0m\u001b[32m[1669406058484905/end/7 (pid 12019)] \u001b[0m\u001b[22mWorkflow finished!\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:23.370 \u001b[0m\u001b[32m[1669406058484905/end/7 (pid 12019)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:54:23.377 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python src/data/feeds_flow.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45148230-bf1d-4a95-8615-ee2ae6b7ab4a",
   "metadata": {},
   "source": [
    "Let's see the resulting data after adding one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "42cae734-98cf-4bc9-9421-0e5d5274b600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run('FeedsFlow/1669406058484905'),\n",
       " Run('FeedsFlow/1669405882277582'),\n",
       " Run('FeedsFlow/1669405615532166')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metaflow import Flow\n",
    "fl = Flow('FeedsFlow')\n",
    "runs_list = list(fl)\n",
    "runs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ccca5c-81e4-4795-ad95-126b7ea9382f",
   "metadata": {},
   "source": [
    "There's a new run with the new features. One of the most important features in metaflow is the experiment versioning. Loading the new execution it is possible to see the newly generated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3bfeb99a-8bc4-4140-a5c3-d15a7d7ea750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>LINK</th>\n",
       "      <th>TIME_PUBLISHED</th>\n",
       "      <th>token_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cardeal investigado por fraude gravou ligação ...</td>\n",
       "      <td>Um &lt;a href=\"https://www1.folha.uol.com.br/mund...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:48:00 -0300</td>\n",
       "      <td>[cardeal, italiano, investigado, crimes, finan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maldição da Copa estraga até os melhores bares</td>\n",
       "      <td>Na Copa do Mundo, como em qualquer outra ocasi...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:32:00 -0300</td>\n",
       "      <td>[copa, mundo, qualquer, outra, ocasião, boteco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fifa divulga dados de público maiores que capa...</td>\n",
       "      <td>Deu no álbum da &lt;a href=\"https://www1.folha.uo...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:28:00 -0300</td>\n",
       "      <td>[deu, álbum, copa, estádios, dedicados, compet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economia libera R$ 37,4 milhões para PF retoma...</td>\n",
       "      <td>O Ministério da Economia editou uma portaria p...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:23:00 -0300</td>\n",
       "      <td>[ministério, economia, editou, portaria, liber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ingleses voltam a protestar contra o racismo a...</td>\n",
       "      <td>Da mesma forma que fizeram na estreia da &lt;a hr...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:15:00 -0300</td>\n",
       "      <td>[mesma, forma, fizeram, estreia, copa, mundo, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Procon suspende atendimentos nesta terça e qua...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/3pgG9TP2ryZosq...</td>\n",
       "      <td>https://g1.globo.com/mg/triangulo-mineiro/noti...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:33:44 -0000</td>\n",
       "      <td>[órgão, passará, atender, rua, perdizes, 280, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Homem persegue esposa com facão após vítima vo...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/3bNJ3sUSiloSnI...</td>\n",
       "      <td>https://g1.globo.com/ro/rondonia/noticia/2018/...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:30:17 -0000</td>\n",
       "      <td>[agressão, aconteceu, madrugada, desta, segund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Quase dois anos após matar grávida e roubar be...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/scebsn6NM18wLX...</td>\n",
       "      <td>https://g1.globo.com/mg/triangulo-mineiro/noti...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:21:41 -0000</td>\n",
       "      <td>[jovem, morta, agosto, 2016., seis, pessoas, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Homem é preso pela Polícia Civil por suspeita ...</td>\n",
       "      <td>Segundo delegado, foram necessárias três seman...</td>\n",
       "      <td>https://g1.globo.com/mg/zona-da-mata/noticia/2...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:06:03 -0000</td>\n",
       "      <td>[segundo, delegado, necessárias, três, semanas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10 mil pessoas foram indenizadas por invalidez...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/L4fE7nlg-zifJe...</td>\n",
       "      <td>https://g1.globo.com/ce/ceara/noticia/2018/07/...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:04:44 -0000</td>\n",
       "      <td>[número, indenizações, ceará, fica, atrás, ape...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TITLE  \\\n",
       "0   Cardeal investigado por fraude gravou ligação ...   \n",
       "1      Maldição da Copa estraga até os melhores bares   \n",
       "2   Fifa divulga dados de público maiores que capa...   \n",
       "3   Economia libera R$ 37,4 milhões para PF retoma...   \n",
       "4   Ingleses voltam a protestar contra o racismo a...   \n",
       "..                                                ...   \n",
       "35  Procon suspende atendimentos nesta terça e qua...   \n",
       "36  Homem persegue esposa com facão após vítima vo...   \n",
       "37  Quase dois anos após matar grávida e roubar be...   \n",
       "38  Homem é preso pela Polícia Civil por suspeita ...   \n",
       "39  10 mil pessoas foram indenizadas por invalidez...   \n",
       "\n",
       "                                              CONTENT  \\\n",
       "0   Um <a href=\"https://www1.folha.uol.com.br/mund...   \n",
       "1   Na Copa do Mundo, como em qualquer outra ocasi...   \n",
       "2   Deu no álbum da <a href=\"https://www1.folha.uo...   \n",
       "3   O Ministério da Economia editou uma portaria p...   \n",
       "4   Da mesma forma que fizeram na estreia da <a hr...   \n",
       "..                                                ...   \n",
       "35  <img src=\"https://s2.glbimg.com/3pgG9TP2ryZosq...   \n",
       "36  <img src=\"https://s2.glbimg.com/3bNJ3sUSiloSnI...   \n",
       "37  <img src=\"https://s2.glbimg.com/scebsn6NM18wLX...   \n",
       "38  Segundo delegado, foram necessárias três seman...   \n",
       "39  <img src=\"https://s2.glbimg.com/L4fE7nlg-zifJe...   \n",
       "\n",
       "                                                 LINK  \\\n",
       "0   https://redir.folha.com.br/redir/online/emcima...   \n",
       "1   https://redir.folha.com.br/redir/online/emcima...   \n",
       "2   https://redir.folha.com.br/redir/online/emcima...   \n",
       "3   https://redir.folha.com.br/redir/online/emcima...   \n",
       "4   https://redir.folha.com.br/redir/online/emcima...   \n",
       "..                                                ...   \n",
       "35  https://g1.globo.com/mg/triangulo-mineiro/noti...   \n",
       "36  https://g1.globo.com/ro/rondonia/noticia/2018/...   \n",
       "37  https://g1.globo.com/mg/triangulo-mineiro/noti...   \n",
       "38  https://g1.globo.com/mg/zona-da-mata/noticia/2...   \n",
       "39  https://g1.globo.com/ce/ceara/noticia/2018/07/...   \n",
       "\n",
       "                     TIME_PUBLISHED  \\\n",
       "0        25 Nov 2022 16:48:00 -0300   \n",
       "1        25 Nov 2022 16:32:00 -0300   \n",
       "2        25 Nov 2022 16:28:00 -0300   \n",
       "3        25 Nov 2022 16:23:00 -0300   \n",
       "4        25 Nov 2022 16:15:00 -0300   \n",
       "..                              ...   \n",
       "35  Mon, 23 Jul 2018 15:33:44 -0000   \n",
       "36  Mon, 23 Jul 2018 15:30:17 -0000   \n",
       "37  Mon, 23 Jul 2018 15:21:41 -0000   \n",
       "38  Mon, 23 Jul 2018 15:06:03 -0000   \n",
       "39  Mon, 23 Jul 2018 15:04:44 -0000   \n",
       "\n",
       "                                            token_set  \n",
       "0   [cardeal, italiano, investigado, crimes, finan...  \n",
       "1   [copa, mundo, qualquer, outra, ocasião, boteco...  \n",
       "2   [deu, álbum, copa, estádios, dedicados, compet...  \n",
       "3   [ministério, economia, editou, portaria, liber...  \n",
       "4   [mesma, forma, fizeram, estreia, copa, mundo, ...  \n",
       "..                                                ...  \n",
       "35  [órgão, passará, atender, rua, perdizes, 280, ...  \n",
       "36  [agressão, aconteceu, madrugada, desta, segund...  \n",
       "37  [jovem, morta, agosto, 2016., seis, pessoas, p...  \n",
       "38  [segundo, delegado, necessárias, três, semanas...  \n",
       "39  [número, indenizações, ceará, fica, atrás, ape...  \n",
       "\n",
       "[180 rows x 5 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metaflow import Run\n",
    "r = fl.latest_run\n",
    "df_r = r.data.results\n",
    "df_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648aca4d-34a2-49de-bcad-94cfe8320b78",
   "metadata": {},
   "source": [
    "### Date conversion\n",
    "\n",
    "As the feeds have different formats for date, let's try to generate an unified date field. Again we load and generate a new file for the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59cc9207-fffd-49be-bba0-2f2c164776a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version \u001b[39;1m^2.1.2\u001b[39;22m for \u001b[36mpendulum\u001b[39m\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[39m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(0.4s)\u001b[39;22m\n",
      "\n",
      "\u001b[34mWriting lock file\u001b[39m\n",
      "\n",
      "No dependencies to install or update\n"
     ]
    }
   ],
   "source": [
    "!poetry add pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9861d394-025e-4b0a-9fd8-e1dd09a29f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring colorama: markers 'sys_platform == \"win32\" and python_full_version == \"3.10.6\" or platform_system == \"Windows\" and python_full_version == \"3.10.6\"' don't match your environment\n",
      "Requirement already satisfied: astroid==2.12.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.12.13)\n",
      "Requirement already satisfied: boto3==1.26.17 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.26.17)\n",
      "Requirement already satisfied: botocore==1.29.17 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.29.17)\n",
      "Requirement already satisfied: certifi==2022.9.24 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer==2.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.1.1)\n",
      "Requirement already satisfied: click==8.1.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (8.1.3)\n",
      "Requirement already satisfied: dill==0.3.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (0.3.6)\n",
      "Requirement already satisfied: feedparser==6.0.10 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (6.0.10)\n",
      "Requirement already satisfied: idna==3.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (3.4)\n",
      "Requirement already satisfied: isort==5.10.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 31)) (5.10.1)\n",
      "Requirement already satisfied: jmespath==1.0.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 34)) (1.0.1)\n",
      "Requirement already satisfied: joblib==1.2.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 37)) (1.2.0)\n",
      "Requirement already satisfied: lazy-object-proxy==1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 40)) (1.8.0)\n",
      "Requirement already satisfied: mccabe==0.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 60)) (0.7.0)\n",
      "Requirement already satisfied: metaflow==2.7.14 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 63)) (2.7.14)\n",
      "Requirement already satisfied: nltk==3.7 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 66)) (3.7)\n",
      "Requirement already satisfied: numpy==1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 69)) (1.23.5)\n",
      "Requirement already satisfied: pandas==1.5.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 98)) (1.5.2)\n",
      "Collecting pendulum==2.1.2\n",
      "  Using cached pendulum-2.1.2.tar.gz (81 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: platformdirs==2.5.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 148)) (2.5.4)\n",
      "Requirement already satisfied: pylint==2.15.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 151)) (2.15.6)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 154)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 157)) (2022.6)\n",
      "Collecting pytzdata==2020.1\n",
      "  Using cached pytzdata-2020.1-py2.py3-none-any.whl (489 kB)\n",
      "Requirement already satisfied: regex==2022.10.31 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 163)) (2022.10.31)\n",
      "Requirement already satisfied: requests==2.28.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 252)) (2.28.1)\n",
      "Requirement already satisfied: s3transfer==0.6.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 255)) (0.6.0)\n",
      "Requirement already satisfied: sgmllib3k==1.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 258)) (1.0.0)\n",
      "Requirement already satisfied: six==1.16.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 260)) (1.16.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 263)) (2.0.1)\n",
      "Requirement already satisfied: tomlkit==0.11.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 266)) (0.11.6)\n",
      "Requirement already satisfied: tqdm==4.64.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 269)) (4.64.1)\n",
      "Requirement already satisfied: urllib3==1.26.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 272)) (1.26.13)\n",
      "Requirement already satisfied: wrapt==1.14.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 275)) (1.14.1)\n",
      "Building wheels for collected packages: pendulum\n",
      "  Building wheel for pendulum (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pendulum: filename=pendulum-2.1.2-cp310-cp310-manylinux_2_35_aarch64.whl size=109777 sha256=e56f007c02e847443349e99d1d4c23da3d0b3b9053001deb244ef8609ce7f160\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/64/1e/bd/79a9fc49d45de83b4f5461dd341749608cb8653f840f9b74dc\n",
      "Successfully built pendulum\n",
      "Installing collected packages: pytzdata, pendulum\n",
      "Successfully installed pendulum-2.1.2 pytzdata-2020.1\n"
     ]
    }
   ],
   "source": [
    "!poetry export -f requirements.txt --output requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c06d053-7a08-4085-ba48-81744e717bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/data/feeds_flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/data/feeds_flow.py\n",
    "# %load src/data/feeds_flow.py\n",
    "\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "import pendulum\n",
    "\n",
    "from metaflow import FlowSpec, step\n",
    "\n",
    "class FeedsFlow(FlowSpec):\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.feeds_url = [\n",
    "            'https://feeds.folha.uol.com.br/emcimadahora/rss091.xml',\n",
    "            'https://g1.globo.com/rss/g1/',\n",
    "            'https://g1.globo.com/rss/g1/brasil'\n",
    "        ]\n",
    "        self.next(self.fetch_feed_data, foreach='feeds_url')\n",
    "\n",
    "    @step\n",
    "    def fetch_feed_data(self):\n",
    "        \n",
    "        print(f\"Downloading from url {self.input}\")\n",
    "        blog_feed = feedparser.parse(self.input)\n",
    "\n",
    "        posts = blog_feed.entries  \n",
    "        post_list = []\n",
    "\n",
    "        for post in posts:\n",
    "            post_dict = dict()\n",
    "\n",
    "            post_dict[\"TITLE\"] = post.title\n",
    "            post_dict[\"CONTENT\"] = post.summary\n",
    "            post_dict[\"LINK\"] = post.link\n",
    "            post_dict[\"TIME_PUBLISHED\"] = post.published\n",
    "            # post_dict[\"TAGS\"] = [tag.term for tag in post.tags]\n",
    "            \n",
    "            # First date conversion try:\n",
    "            dt = None\n",
    "            try:\n",
    "                dt = pendulum.from_format(post.published, 'DD MMM YYYY HH:mm:ss ZZ') \n",
    "            except ValueError as e:\n",
    "                dt = pendulum.from_format(post.published, 'ddd, DD MMM YYYY HH:mm:ss ZZ')\n",
    "            except ValueError as e:\n",
    "                print(f\"Formating error!\\n{e}\")\n",
    "            post_dict['PUBLISHED'] = dt\n",
    "\n",
    "            post_list.append(post_dict)\n",
    "        self.posts = pd.DataFrame(post_list)        \n",
    "        self.next(self.feeds_aggregate)\n",
    "\n",
    "    @step\n",
    "    def feeds_aggregate(self, inputs):\n",
    "        self.results = pd.concat([input.posts for input in inputs])\n",
    "        self.next(self.preprocess_pandas)\n",
    "              \n",
    "    @step\n",
    "    def preprocess_pandas(self):\n",
    "        stop = set(stopwords.words('portuguese') + list(string.punctuation))\n",
    "        stop.update(['http', 'pro', 'https', 't.', 'co'])\n",
    "\n",
    "        def preprocess(words):\n",
    "            # Remove HTML marks\n",
    "            words = re.sub('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', '', words)\n",
    "            tokens = word_tokenize(words)\n",
    "            tokens = [word for word in tokens if word not in stop]\n",
    "            tokens = [word for word in tokens if re.search(r'\\w+', word) and len(word) > 2]\n",
    "            return tokens\n",
    "    \n",
    "        self.results['token_set'] = self.results.apply(lambda row: preprocess(row.CONTENT.lower()), axis=1)\n",
    "        print(\"Tokenization finished!\")\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        print('Workflow finished!')\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    FeedsFlow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "72c2ef47-f1a2-43f9-85ef-583698249360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.14\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mFeedsFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:jovyan\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:03.939 \u001b[0m\u001b[1mWorkflow starting (run-id 1669406103878472):\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:03.964 \u001b[0m\u001b[32m[1669406103878472/start/1 (pid 12042)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:04.682 \u001b[0m\u001b[32m[1669406103878472/start/1 (pid 12042)] \u001b[0m\u001b[1mForeach yields 3 child steps.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:04.682 \u001b[0m\u001b[32m[1669406103878472/start/1 (pid 12042)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:04.716 \u001b[0m\u001b[32m[1669406103878472/fetch_feed_data/2 (pid 12053)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:04.736 \u001b[0m\u001b[32m[1669406103878472/fetch_feed_data/3 (pid 12054)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:04.775 \u001b[0m\u001b[32m[1669406103878472/fetch_feed_data/4 (pid 12055)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:05.577 \u001b[0m\u001b[32m[1669406103878472/fetch_feed_data/2 (pid 12053)] \u001b[0m\u001b[22mDownloading from url https://feeds.folha.uol.com.br/emcimadahora/rss091.xml\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:05.584 \u001b[0m\u001b[32m[1669406103878472/fetch_feed_data/3 (pid 12054)] \u001b[0m\u001b[22mDownloading from url https://g1.globo.com/rss/g1/\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:05.804 \u001b[0m\u001b[32m[1669406103878472/fetch_feed_data/4 (pid 12055)] \u001b[0m\u001b[22mDownloading from url https://g1.globo.com/rss/g1/brasil\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:05.990 \u001b[0m\u001b[32m[1669406103878472/fetch_feed_data/3 (pid 12054)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:06.045 \u001b[0m\u001b[32m[1669406103878472/fetch_feed_data/2 (pid 12053)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:06.205 \u001b[0m\u001b[32m[1669406103878472/fetch_feed_data/4 (pid 12055)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:06.244 \u001b[0m\u001b[32m[1669406103878472/feeds_aggregate/5 (pid 12065)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:07.025 \u001b[0m\u001b[32m[1669406103878472/feeds_aggregate/5 (pid 12065)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:07.057 \u001b[0m\u001b[32m[1669406103878472/preprocess_pandas/6 (pid 12069)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:07.764 \u001b[0m\u001b[32m[1669406103878472/preprocess_pandas/6 (pid 12069)] \u001b[0m\u001b[22mTokenization finished!\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:07.946 \u001b[0m\u001b[32m[1669406103878472/preprocess_pandas/6 (pid 12069)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:07.979 \u001b[0m\u001b[32m[1669406103878472/end/7 (pid 12073)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:08.521 \u001b[0m\u001b[32m[1669406103878472/end/7 (pid 12073)] \u001b[0m\u001b[22mWorkflow finished!\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:08.671 \u001b[0m\u001b[32m[1669406103878472/end/7 (pid 12073)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-25 19:55:08.678 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python src/data/feeds_flow.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313becf8-3b65-4baa-947a-4694cd4fc255",
   "metadata": {},
   "source": [
    "Let's see again the output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "08de6cea-5daf-4956-b158-148e92edbd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run('FeedsFlow/1669406103878472'),\n",
       " Run('FeedsFlow/1669406058484905'),\n",
       " Run('FeedsFlow/1669405882277582'),\n",
       " Run('FeedsFlow/1669405615532166')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metaflow import Flow\n",
    "fl = Flow('FeedsFlow')\n",
    "runs_list = list(fl)\n",
    "runs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "887a9ef0-544a-4e18-beab-cced1ee01aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>LINK</th>\n",
       "      <th>TIME_PUBLISHED</th>\n",
       "      <th>PUBLISHED</th>\n",
       "      <th>token_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cardeal investigado por fraude gravou ligação ...</td>\n",
       "      <td>Um &lt;a href=\"https://www1.folha.uol.com.br/mund...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:48:00 -0300</td>\n",
       "      <td>2022-11-25 16:48:00-03:00</td>\n",
       "      <td>[cardeal, italiano, investigado, crimes, finan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maldição da Copa estraga até os melhores bares</td>\n",
       "      <td>Na Copa do Mundo, como em qualquer outra ocasi...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:32:00 -0300</td>\n",
       "      <td>2022-11-25 16:32:00-03:00</td>\n",
       "      <td>[copa, mundo, qualquer, outra, ocasião, boteco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fifa divulga dados de público maiores que capa...</td>\n",
       "      <td>Deu no álbum da &lt;a href=\"https://www1.folha.uo...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:28:00 -0300</td>\n",
       "      <td>2022-11-25 16:28:00-03:00</td>\n",
       "      <td>[deu, álbum, copa, estádios, dedicados, compet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economia libera R$ 37,4 milhões para PF retoma...</td>\n",
       "      <td>O Ministério da Economia editou uma portaria p...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:23:00 -0300</td>\n",
       "      <td>2022-11-25 16:23:00-03:00</td>\n",
       "      <td>[ministério, economia, editou, portaria, liber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ingleses voltam a protestar contra o racismo a...</td>\n",
       "      <td>Da mesma forma que fizeram na estreia da &lt;a hr...</td>\n",
       "      <td>https://redir.folha.com.br/redir/online/emcima...</td>\n",
       "      <td>25 Nov 2022 16:15:00 -0300</td>\n",
       "      <td>2022-11-25 16:15:00-03:00</td>\n",
       "      <td>[mesma, forma, fizeram, estreia, copa, mundo, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Procon suspende atendimentos nesta terça e qua...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/3pgG9TP2ryZosq...</td>\n",
       "      <td>https://g1.globo.com/mg/triangulo-mineiro/noti...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:33:44 -0000</td>\n",
       "      <td>2018-07-23 15:33:44+00:00</td>\n",
       "      <td>[órgão, passará, atender, rua, perdizes, 280, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Homem persegue esposa com facão após vítima vo...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/3bNJ3sUSiloSnI...</td>\n",
       "      <td>https://g1.globo.com/ro/rondonia/noticia/2018/...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:30:17 -0000</td>\n",
       "      <td>2018-07-23 15:30:17+00:00</td>\n",
       "      <td>[agressão, aconteceu, madrugada, desta, segund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Quase dois anos após matar grávida e roubar be...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/scebsn6NM18wLX...</td>\n",
       "      <td>https://g1.globo.com/mg/triangulo-mineiro/noti...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:21:41 -0000</td>\n",
       "      <td>2018-07-23 15:21:41+00:00</td>\n",
       "      <td>[jovem, morta, agosto, 2016., seis, pessoas, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Homem é preso pela Polícia Civil por suspeita ...</td>\n",
       "      <td>Segundo delegado, foram necessárias três seman...</td>\n",
       "      <td>https://g1.globo.com/mg/zona-da-mata/noticia/2...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:06:03 -0000</td>\n",
       "      <td>2018-07-23 15:06:03+00:00</td>\n",
       "      <td>[segundo, delegado, necessárias, três, semanas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10 mil pessoas foram indenizadas por invalidez...</td>\n",
       "      <td>&lt;img src=\"https://s2.glbimg.com/L4fE7nlg-zifJe...</td>\n",
       "      <td>https://g1.globo.com/ce/ceara/noticia/2018/07/...</td>\n",
       "      <td>Mon, 23 Jul 2018 15:04:44 -0000</td>\n",
       "      <td>2018-07-23 15:04:44+00:00</td>\n",
       "      <td>[número, indenizações, ceará, fica, atrás, ape...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TITLE  \\\n",
       "0   Cardeal investigado por fraude gravou ligação ...   \n",
       "1      Maldição da Copa estraga até os melhores bares   \n",
       "2   Fifa divulga dados de público maiores que capa...   \n",
       "3   Economia libera R$ 37,4 milhões para PF retoma...   \n",
       "4   Ingleses voltam a protestar contra o racismo a...   \n",
       "..                                                ...   \n",
       "35  Procon suspende atendimentos nesta terça e qua...   \n",
       "36  Homem persegue esposa com facão após vítima vo...   \n",
       "37  Quase dois anos após matar grávida e roubar be...   \n",
       "38  Homem é preso pela Polícia Civil por suspeita ...   \n",
       "39  10 mil pessoas foram indenizadas por invalidez...   \n",
       "\n",
       "                                              CONTENT  \\\n",
       "0   Um <a href=\"https://www1.folha.uol.com.br/mund...   \n",
       "1   Na Copa do Mundo, como em qualquer outra ocasi...   \n",
       "2   Deu no álbum da <a href=\"https://www1.folha.uo...   \n",
       "3   O Ministério da Economia editou uma portaria p...   \n",
       "4   Da mesma forma que fizeram na estreia da <a hr...   \n",
       "..                                                ...   \n",
       "35  <img src=\"https://s2.glbimg.com/3pgG9TP2ryZosq...   \n",
       "36  <img src=\"https://s2.glbimg.com/3bNJ3sUSiloSnI...   \n",
       "37  <img src=\"https://s2.glbimg.com/scebsn6NM18wLX...   \n",
       "38  Segundo delegado, foram necessárias três seman...   \n",
       "39  <img src=\"https://s2.glbimg.com/L4fE7nlg-zifJe...   \n",
       "\n",
       "                                                 LINK  \\\n",
       "0   https://redir.folha.com.br/redir/online/emcima...   \n",
       "1   https://redir.folha.com.br/redir/online/emcima...   \n",
       "2   https://redir.folha.com.br/redir/online/emcima...   \n",
       "3   https://redir.folha.com.br/redir/online/emcima...   \n",
       "4   https://redir.folha.com.br/redir/online/emcima...   \n",
       "..                                                ...   \n",
       "35  https://g1.globo.com/mg/triangulo-mineiro/noti...   \n",
       "36  https://g1.globo.com/ro/rondonia/noticia/2018/...   \n",
       "37  https://g1.globo.com/mg/triangulo-mineiro/noti...   \n",
       "38  https://g1.globo.com/mg/zona-da-mata/noticia/2...   \n",
       "39  https://g1.globo.com/ce/ceara/noticia/2018/07/...   \n",
       "\n",
       "                     TIME_PUBLISHED                  PUBLISHED  \\\n",
       "0        25 Nov 2022 16:48:00 -0300  2022-11-25 16:48:00-03:00   \n",
       "1        25 Nov 2022 16:32:00 -0300  2022-11-25 16:32:00-03:00   \n",
       "2        25 Nov 2022 16:28:00 -0300  2022-11-25 16:28:00-03:00   \n",
       "3        25 Nov 2022 16:23:00 -0300  2022-11-25 16:23:00-03:00   \n",
       "4        25 Nov 2022 16:15:00 -0300  2022-11-25 16:15:00-03:00   \n",
       "..                              ...                        ...   \n",
       "35  Mon, 23 Jul 2018 15:33:44 -0000  2018-07-23 15:33:44+00:00   \n",
       "36  Mon, 23 Jul 2018 15:30:17 -0000  2018-07-23 15:30:17+00:00   \n",
       "37  Mon, 23 Jul 2018 15:21:41 -0000  2018-07-23 15:21:41+00:00   \n",
       "38  Mon, 23 Jul 2018 15:06:03 -0000  2018-07-23 15:06:03+00:00   \n",
       "39  Mon, 23 Jul 2018 15:04:44 -0000  2018-07-23 15:04:44+00:00   \n",
       "\n",
       "                                            token_set  \n",
       "0   [cardeal, italiano, investigado, crimes, finan...  \n",
       "1   [copa, mundo, qualquer, outra, ocasião, boteco...  \n",
       "2   [deu, álbum, copa, estádios, dedicados, compet...  \n",
       "3   [ministério, economia, editou, portaria, liber...  \n",
       "4   [mesma, forma, fizeram, estreia, copa, mundo, ...  \n",
       "..                                                ...  \n",
       "35  [órgão, passará, atender, rua, perdizes, 280, ...  \n",
       "36  [agressão, aconteceu, madrugada, desta, segund...  \n",
       "37  [jovem, morta, agosto, 2016., seis, pessoas, p...  \n",
       "38  [segundo, delegado, necessárias, três, semanas...  \n",
       "39  [número, indenizações, ceará, fica, atrás, ape...  \n",
       "\n",
       "[180 rows x 6 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metaflow import Run\n",
    "r = fl.latest_run\n",
    "df_r = r.data.results\n",
    "df_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00737004-6a69-4fb4-a350-f9baf16489e1",
   "metadata": {},
   "source": [
    "### Final basic flow\n",
    "\n",
    "Let's visualize it and see hot the basic flow stands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b096ec9-96e4-4656-b934-10633b87e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
      "\n",
      "        mamba (0.27.0) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "█████████████████████████████████████████████████████████████\n",
      "\n",
      "\n",
      "Looking for: ['graphviz']\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.3s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.3s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m 490.0 B /  ??.?MB @   1.9kB/s  0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\n",
      "conda-forge/linux-aarch64 \u001b[90m━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.4s\n",
      "conda-forge/noarch        \u001b[90m━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━━\u001b[0m 319.1kB /  ??.?MB @ 882.4kB/s  0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m  50.3kB /  ??.?MB @ 110.1kB/s  0.5s\n",
      "conda-forge/noarch        \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m 654.8kB /  ??.?MB @   1.4MB/s  0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m  90.9kB /  ??.?MB @ 152.8kB/s  0.6s\n",
      "conda-forge/noarch        \u001b[90m━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m 814.6kB /  ??.?MB @   1.4MB/s  0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━\u001b[0m 227.5kB /  ??.?MB @ 326.5kB/s  0.7s\n",
      "conda-forge/noarch        \u001b[90m━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━\u001b[0m   1.4MB /  ??.?MB @   2.0MB/s  0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m 469.5kB /  ??.?MB @ 588.3kB/s  0.8s\n",
      "conda-forge/noarch        \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m   1.5MB /  ??.?MB @   2.0MB/s  0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m 787.4kB /  ??.?MB @ 876.2kB/s  0.9s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   1.8MB /  ??.?MB @   2.2MB/s  0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m 937.0kB /  ??.?MB @ 985.8kB/s  1.0s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   2.2MB /  ??.?MB @   2.3MB/s  1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m   1.2MB /  ??.?MB @   1.2MB/s  1.1s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m   2.5MB /  ??.?MB @   2.3MB/s  1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m   1.5MB /  ??.?MB @   1.3MB/s  1.2s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m   2.7MB /  ??.?MB @   2.4MB/s  1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   1.9MB /  ??.?MB @   1.5MB/s  1.3s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   3.0MB /  ??.?MB @   2.4MB/s  1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   1.9MB /  ??.?MB @   1.5MB/s  1.4s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   3.0MB /  ??.?MB @   2.4MB/s  1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\n",
      "conda-forge/linux-aarch64 \u001b[90m╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m   2.5MB /  ??.?MB @   1.7MB/s  1.5s\n",
      "conda-forge/noarch        \u001b[90m╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m   3.6MB /  ??.?MB @   2.4MB/s  1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m   2.8MB /  ??.?MB @   1.8MB/s  1.6s\n",
      "conda-forge/noarch        \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m   3.9MB /  ??.?MB @   2.5MB/s  1.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   3.0MB /  ??.?MB @   1.8MB/s  1.7s\n",
      "conda-forge/noarch        \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   4.2MB /  ??.?MB @   2.5MB/s  1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   3.2MB /  ??.?MB @   1.8MB/s  1.8s\n",
      "conda-forge/noarch        \u001b[90m━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━\u001b[0m   4.5MB /  ??.?MB @   2.5MB/s  1.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m   3.4MB /  ??.?MB @   1.8MB/s  1.9s\n",
      "conda-forge/noarch        \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m   4.8MB /  ??.?MB @   2.5MB/s  1.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m   3.7MB /  ??.?MB @   1.9MB/s  2.0s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   5.1MB /  ??.?MB @   2.6MB/s  2.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   3.9MB /  ??.?MB @   1.9MB/s  2.1s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   5.3MB /  ??.?MB @   2.6MB/s  2.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m   4.3MB /  ??.?MB @   2.0MB/s  2.2s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m   5.6MB /  ??.?MB @   2.6MB/s  2.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m   4.6MB /  ??.?MB @   2.0MB/s  2.3s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m   5.9MB /  ??.?MB @   2.6MB/s  2.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
      "conda-forge/linux-aarch64 \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   4.9MB /  ??.?MB @   2.1MB/s  2.4s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   6.2MB /  ??.?MB @   2.6MB/s  2.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
      "conda-forge/linux-aarch64 \u001b[90m╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m   5.3MB /  ??.?MB @   2.1MB/s  2.5s\n",
      "conda-forge/noarch        \u001b[90m╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m   6.5MB /  ??.?MB @   2.6MB/s  2.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m   5.6MB /  ??.?MB @   2.1MB/s  2.6s\n",
      "conda-forge/noarch        \u001b[90m━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m   6.8MB /  ??.?MB @   2.6MB/s  2.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   5.9MB /  ??.?MB @   2.2MB/s  2.7s\n",
      "conda-forge/noarch        \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━\u001b[0m   7.0MB /  ??.?MB @   2.6MB/s  2.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m   6.0MB /  ??.?MB @   2.2MB/s  2.8s\n",
      "conda-forge/noarch        \u001b[90m━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━\u001b[0m   7.2MB /  ??.?MB @   2.6MB/s  2.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━\u001b[0m   6.3MB /  ??.?MB @   2.2MB/s  2.9s\n",
      "conda-forge/noarch        \u001b[90m━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━\u001b[0m   7.5MB /  ??.?MB @   2.6MB/s  2.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
      "conda-forge/linux-aarch64 \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━\u001b[0m   6.5MB /  ??.?MB @   2.2MB/s  3.0s\n",
      "conda-forge/noarch        \u001b[90m━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━\u001b[0m   7.8MB /  ??.?MB @   2.6MB/s  3.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
      "conda-forge/linux-aarch64 ━━━━━━━━━━━━━━━━━   6.9MB @   2.2MB/s Finalizing  3.1s\n",
      "conda-forge/noarch        \u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   8.1MB @   2.6MB/s             3.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-aarch64                          @   2.2MB/s  3.1s\n",
      "[+] 3.2s\n",
      "conda-forge/noarch \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m   8.4MB /  ??.?MB @   2.6MB/s  3.2s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
      "conda-forge/noarch \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m   8.7MB /  ??.?MB @   2.6MB/s  3.3s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
      "conda-forge/noarch \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m   8.9MB /  ??.?MB @   2.6MB/s  3.4s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
      "conda-forge/noarch \u001b[90m╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m   9.0MB /  ??.?MB @   2.7MB/s  3.5s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
      "conda-forge/noarch \u001b[90m━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m   9.4MB /  ??.?MB @   2.6MB/s  3.6s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
      "conda-forge/noarch \u001b[90m━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m   9.8MB /  ??.?MB @   2.7MB/s  3.7s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
      "conda-forge/noarch \u001b[90m━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m   9.9MB /  ??.?MB @   2.6MB/s  3.8s\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.9s\n",
      "conda-forge/noarch \u001b[90m━━━━━━━━━╸\u001b[0m\u001b[33m━━━━━━━━━━━━━━━\u001b[0m  10.2MB /  ??.?MB @   2.7MB/s  3.9s\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                  10.4MB @   2.7MB/s  4.0s\n",
      "\u001b[?25h\n",
      "Pinned packages:\n",
      "  - python 3.10.*\n",
      "  - python 3.10.6\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /opt/conda\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - graphviz\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package                      Version  Build               Channel                        Size\n",
      "─────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "─────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[32m  + atk-1.0                  \u001b[00m   2.38.0  hf4e84e4_1          conda-forge/linux-aarch64     538kB\n",
      "\u001b[32m  + cairo                    \u001b[00m   1.16.0  hd19fb6e_1014       conda-forge/linux-aarch64       2MB\n",
      "\u001b[32m  + expat                    \u001b[00m    2.5.0  ha18d298_0          conda-forge/linux-aarch64     167kB\n",
      "\u001b[32m  + fmt                      \u001b[00m    9.1.0  hdd96247_0          conda-forge/linux-aarch64     190kB\n",
      "\u001b[32m  + font-ttf-dejavu-sans-mono\u001b[00m     2.37  hab24e00_0          conda-forge/noarch            397kB\n",
      "\u001b[32m  + font-ttf-inconsolata     \u001b[00m    3.000  h77eed37_0          conda-forge/noarch             97kB\n",
      "\u001b[32m  + font-ttf-source-code-pro \u001b[00m    2.038  h77eed37_0          conda-forge/noarch            701kB\n",
      "\u001b[32m  + font-ttf-ubuntu          \u001b[00m     0.83  hab24e00_0          conda-forge/noarch              2MB\n",
      "\u001b[32m  + fontconfig               \u001b[00m   2.14.1  h77febde_0          conda-forge/linux-aarch64     364kB\n",
      "\u001b[32m  + fonts-conda-ecosystem    \u001b[00m        1  0                   conda-forge/noarch              4kB\n",
      "\u001b[32m  + fonts-conda-forge        \u001b[00m        1  0                   conda-forge/noarch              4kB\n",
      "\u001b[32m  + freetype                 \u001b[00m   2.12.1  hbbbf32d_1          conda-forge/linux-aarch64     639kB\n",
      "\u001b[32m  + fribidi                  \u001b[00m   1.0.10  hb9de7d4_0          conda-forge/linux-aarch64     116kB\n",
      "\u001b[32m  + gdk-pixbuf               \u001b[00m   2.42.8  hb98dc3c_0          conda-forge/linux-aarch64     619kB\n",
      "\u001b[32m  + gettext                  \u001b[00m   0.21.1  ha18d298_0          conda-forge/linux-aarch64       5MB\n",
      "\u001b[32m  + giflib                   \u001b[00m    5.2.1  hb9de7d4_2          conda-forge/linux-aarch64      80kB\n",
      "\u001b[32m  + graphite2                \u001b[00m   1.3.13  h7fd3ca4_1001       conda-forge/linux-aarch64     107kB\n",
      "\u001b[32m  + graphviz                 \u001b[00m    6.0.2  h7bf13eb_0          conda-forge/linux-aarch64       2MB\n",
      "\u001b[32m  + gtk2                     \u001b[00m  2.24.33  h49e3f37_2          conda-forge/linux-aarch64       8MB\n",
      "\u001b[32m  + gts                      \u001b[00m    0.7.6  hb6842a0_2          conda-forge/linux-aarch64     457kB\n",
      "\u001b[32m  + harfbuzz                 \u001b[00m    5.3.0  h6f3452c_0          conda-forge/linux-aarch64       2MB\n",
      "\u001b[32m  + jpeg                     \u001b[00m       9e  h9cdd2b7_2          conda-forge/linux-aarch64     484kB\n",
      "\u001b[32m  + lerc                     \u001b[00m    4.0.0  h4de3ea5_0          conda-forge/linux-aarch64     262kB\n",
      "\u001b[32m  + libdeflate               \u001b[00m     1.14  h4e544f5_0          conda-forge/linux-aarch64     101kB\n",
      "\u001b[32m  + libgd                    \u001b[00m    2.3.3  h1aa4b80_3          conda-forge/linux-aarch64     309kB\n",
      "\u001b[32m  + libglib                  \u001b[00m   2.74.1  h01e6fbd_1          conda-forge/linux-aarch64       3MB\n",
      "\u001b[32m  + libpng                   \u001b[00m   1.6.39  hf9034f9_0          conda-forge/linux-aarch64     299kB\n",
      "\u001b[32m  + librsvg                  \u001b[00m   2.54.4  h3ad45c2_0          conda-forge/linux-aarch64      10MB\n",
      "\u001b[32m  + libtiff                  \u001b[00m    4.4.0  hacef7f3_4          conda-forge/linux-aarch64     778kB\n",
      "\u001b[32m  + libtool                  \u001b[00m    2.4.6  h01db608_1008       conda-forge/linux-aarch64     552kB\n",
      "\u001b[32m  + libwebp                  \u001b[00m    1.2.4  hef792ef_0          conda-forge/linux-aarch64     101kB\n",
      "\u001b[32m  + libwebp-base             \u001b[00m    1.2.4  h4e544f5_0          conda-forge/linux-aarch64     437kB\n",
      "\u001b[32m  + libxcb                   \u001b[00m     1.13  h3557bc0_1004       conda-forge/linux-aarch64     413kB\n",
      "\u001b[32m  + pango                    \u001b[00m  1.50.12  h3f2bcdb_0          conda-forge/linux-aarch64     444kB\n",
      "\u001b[32m  + pcre2                    \u001b[00m    10.40  he7b27c6_0          conda-forge/linux-aarch64       2MB\n",
      "\u001b[32m  + pixman                   \u001b[00m   0.40.0  hb9de7d4_0          conda-forge/linux-aarch64     551kB\n",
      "\u001b[32m  + pthread-stubs            \u001b[00m      0.4  hb9de7d4_1001       conda-forge/linux-aarch64       6kB\n",
      "\u001b[32m  + xorg-kbproto             \u001b[00m    1.0.7  h3557bc0_1002       conda-forge/linux-aarch64      27kB\n",
      "\u001b[32m  + xorg-libice              \u001b[00m   1.0.10  h3557bc0_0          conda-forge/linux-aarch64      61kB\n",
      "\u001b[32m  + xorg-libsm               \u001b[00m    1.2.3  h965e137_1000       conda-forge/linux-aarch64      27kB\n",
      "\u001b[32m  + xorg-libx11              \u001b[00m    1.7.2  h3557bc0_0          conda-forge/linux-aarch64     983kB\n",
      "\u001b[32m  + xorg-libxau              \u001b[00m    1.0.9  h3557bc0_0          conda-forge/linux-aarch64      14kB\n",
      "\u001b[32m  + xorg-libxdmcp            \u001b[00m    1.1.3  h3557bc0_0          conda-forge/linux-aarch64      20kB\n",
      "\u001b[32m  + xorg-libxext             \u001b[00m    1.3.4  h3557bc0_1          conda-forge/linux-aarch64      54kB\n",
      "\u001b[32m  + xorg-libxrender          \u001b[00m   0.9.10  h3557bc0_1003       conda-forge/linux-aarch64      34kB\n",
      "\u001b[32m  + xorg-renderproto         \u001b[00m   0.11.1  h3557bc0_1002       conda-forge/linux-aarch64      10kB\n",
      "\u001b[32m  + xorg-xextproto           \u001b[00m    7.3.0  h3557bc0_1002       conda-forge/linux-aarch64      28kB\n",
      "\u001b[32m  + xorg-xproto              \u001b[00m   7.0.31  h3557bc0_1007       conda-forge/linux-aarch64      75kB\n",
      "\n",
      "  Change:\n",
      "─────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[31m  - krb5                     \u001b[00m   1.19.3  h7c456eb_0          conda-forge                        \n",
      "\u001b[32m  + krb5                     \u001b[00m   1.19.3  h750e270_0          conda-forge/linux-aarch64       2MB\n",
      "\u001b[31m  - libarchive               \u001b[00m    3.5.2  h610d84a_3          conda-forge                        \n",
      "\u001b[32m  + libarchive               \u001b[00m    3.5.2  hc5648f3_3          conda-forge/linux-aarch64       2MB\n",
      "\u001b[31m  - libcurl                  \u001b[00m   7.86.0  h8fd98b7_0          conda-forge                        \n",
      "\u001b[32m  + libcurl                  \u001b[00m   7.86.0  h22f3f83_1          conda-forge/linux-aarch64     372kB\n",
      "\u001b[31m  - libnghttp2               \u001b[00m   1.47.0  h4173d3e_1          conda-forge                        \n",
      "\u001b[32m  + libnghttp2               \u001b[00m   1.47.0  h674c3cc_1          conda-forge/linux-aarch64     985kB\n",
      "\u001b[31m  - libssh2                  \u001b[00m   1.10.0  h4bb3959_3          conda-forge                        \n",
      "\u001b[32m  + libssh2                  \u001b[00m   1.10.0  he5a64b1_3          conda-forge/linux-aarch64     248kB\n",
      "\u001b[31m  - pycurl                   \u001b[00m   7.45.1  py310h0dc3a97_2     conda-forge                        \n",
      "\u001b[32m  + pycurl                   \u001b[00m   7.45.1  py310hd403cd2_3     conda-forge/linux-aarch64      78kB\n",
      "\u001b[31m  - python                   \u001b[00m   3.10.6  h023d47c_0_cpython  conda-forge                        \n",
      "\u001b[32m  + python                   \u001b[00m   3.10.6  h92ab765_0_cpython  conda-forge/linux-aarch64      14MB\n",
      "\n",
      "  Upgrade:\n",
      "─────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[31m  - cryptography             \u001b[00m   38.0.2  py310h6991d6a_1     conda-forge                        \n",
      "\u001b[32m  + cryptography             \u001b[00m   38.0.4  py310h674ca28_0     conda-forge/linux-aarch64       1MB\n",
      "\u001b[31m  - libmamba                 \u001b[00m   0.27.0  hfcbcd16_0          conda-forge                        \n",
      "\u001b[32m  + libmamba                 \u001b[00m    1.0.0  h4a614fe_2          conda-forge/linux-aarch64       2MB\n",
      "\u001b[31m  - libmambapy               \u001b[00m   0.27.0  py310h76fea7e_0     conda-forge                        \n",
      "\u001b[32m  + libmambapy               \u001b[00m    1.0.0  py310h9c2a01b_2     conda-forge/linux-aarch64     289kB\n",
      "\u001b[31m  - mamba                    \u001b[00m   0.27.0  py310hcf12e44_0     conda-forge                        \n",
      "\u001b[32m  + mamba                    \u001b[00m    1.0.0  py310hcbdc16a_2     conda-forge/linux-aarch64      49kB\n",
      "\u001b[31m  - nodejs                   \u001b[00m  18.11.0  he850d6a_0          conda-forge                        \n",
      "\u001b[32m  + nodejs                   \u001b[00m  18.12.1  h928fb59_0          conda-forge/linux-aarch64      18MB\n",
      "\u001b[31m  - openssl                  \u001b[00m   1.1.1q  h4e544f5_1          conda-forge                        \n",
      "\u001b[32m  + openssl                  \u001b[00m    3.0.7  h4e544f5_0          conda-forge/linux-aarch64       3MB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 48 packages\n",
      "  Change: 7 packages\n",
      "  Upgrade: 6 packages\n",
      "\n",
      "  Total download: 91MB\n",
      "\n",
      "─────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
      "Downloading      \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B                            0.0s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
      "Downloading  (5) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B expat                      0.0s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\n",
      "Downloading  (5) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   0.0 B expat                      0.1s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.3s\n",
      "Downloading  (5) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 360.4kB expat                      0.2s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\n",
      "Downloading  (5) \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 897.9kB expat                      0.3s\n",
      "Extracting       \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m       0                            0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gfmt                                                190.1kB @ 408.7kB/s  0.5s\n",
      "[+] 0.5s\n",
      "Downloading  (5) \u001b[33m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   2.2MB lerc                       0.4s\n",
      "Extracting   (1) \u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m       0 fmt                        0.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gopenssl                                              2.9MB @   5.0MB/s  0.6s\n",
      "[+] 0.6s\n",
      "Downloading  (5) \u001b[33m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m   3.4MB lerc                       0.5s\n",
      "Extracting   (2) \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m       0 fmt                        0.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpixman                                             551.2kB @ 865.2kB/s  0.6s\n",
      "expat                                              167.3kB @ 253.1kB/s  0.7s\n",
      "[+] 0.7s\n",
      "Downloading  (5) \u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m   3.9MB lerc                       0.6s\n",
      "Extracting   (4) \u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m       0 fmt                        0.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glerc                                               262.1kB @ 368.9kB/s  0.2s\n",
      "xorg-renderproto                                     9.6kB @  12.4kB/s  0.2s\n",
      "[+] 0.8s\n",
      "Downloading  (5) \u001b[33m━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m   4.1MB libwebp-base               0.7s\n",
      "Extracting   (5) \u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m       1 expat                      0.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gxorg-xproto                                         74.8kB @  89.5kB/s  0.2s\n",
      "[+] 0.9s\n",
      "Downloading  (5) \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m   4.2MB libwebp-base               0.8s\n",
      "Extracting   (6) \u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m       1 expat                      0.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gxorg-libxdmcp                                       19.9kB @  20.7kB/s  0.3s\n",
      "[+] 1.0s\n",
      "Downloading  (5) \u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m   4.3MB libwebp-base               0.9s\n",
      "Extracting   (7) \u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m       1 expat                      0.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n",
      "Downloading  (5) ╸\u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m   5.1MB libwebp-base               1.0s\n",
      "Extracting   (6) \u001b[33m━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m       2 expat                      0.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gxorg-libice                                         61.5kB @  56.0kB/s  0.4s\n",
      "[+] 1.2s\n",
      "Downloading  (5) ╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m   6.4MB nodejs                     1.1s\n",
      "Extracting   (7) \u001b[33m━━━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m       2 lerc                       0.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\n",
      "Downloading  (5) ╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m   7.6MB nodejs                     1.2s\n",
      "Extracting   (6) ╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m       3 lerc                       0.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\n",
      "Downloading  (5) ━╸\u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m   8.9MB nodejs                     1.3s\n",
      "Extracting   (5) ╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m       4 expat                      0.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibcurl                                            371.6kB @ 267.5kB/s  0.3s\n",
      "[+] 1.5s\n",
      "Downloading  (5) ━╸\u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m  10.1MB nodejs                     1.4s\n",
      "Extracting   (6) ╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m       4 expat                      1.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibwebp-base                                       437.3kB @ 289.2kB/s  1.5s\n",
      "[+] 1.6s\n",
      "Downloading  (5) ━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m  11.6MB python                     1.5s\n",
      "Extracting   (7) ╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m       4 expat                      1.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
      "Downloading  (5) ━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m  12.1MB python                     1.6s\n",
      "Extracting   (6) ╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m       5 expat                      1.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
      "Downloading  (5) ━━╸\u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m  13.0MB python                     1.7s\n",
      "Extracting   (5) ━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m       6 libcurl                    1.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
      "Downloading  (5) ━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m  14.1MB python                     1.8s\n",
      "Extracting   (5) ━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m       6 libcurl                    1.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gatk-1.0                                            537.7kB @ 279.0kB/s  0.5s\n",
      "[+] 2.0s\n",
      "Downloading  (5) ━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m  15.4MB gdk-pixbuf                 1.9s\n",
      "Extracting   (6) ━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m       6 libcurl                    1.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
      "Downloading  (5) ━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m  16.7MB gdk-pixbuf                 2.0s\n",
      "Extracting   (5) ━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m       7 libcurl                    1.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibtiff                                            777.9kB @ 359.4kB/s  1.2s\n",
      "[+] 2.2s\n",
      "Downloading  (5) ━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m  18.2MB gdk-pixbuf                 2.1s\n",
      "Extracting   (5) ━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m       8 libtiff                    1.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
      "Downloading  (5) ━━━╸\u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m  19.7MB gdk-pixbuf                 2.2s\n",
      "Extracting   (4) ━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m       9 libtiff                    1.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
      "Downloading  (5) ━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m  20.9MB libmamba                   2.3s\n",
      "Extracting   (4) ━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m       9 libtiff                    1.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
      "Downloading  (5) ━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m  22.2MB libmamba                   2.4s\n",
      "Extracting   (4) ━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m       9 libtiff                    2.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ggdk-pixbuf                                         618.5kB @ 239.4kB/s  1.1s\n",
      "[+] 2.6s\n",
      "Downloading  (5) ━━━━╸\u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m  23.7MB libmamba                   2.5s\n",
      "Extracting   (3) ━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m      10 atk-1.0                    2.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibmambapy                                         289.1kB @ 109.6kB/s  0.5s\n",
      "[+] 2.7s\n",
      "Downloading  (5) ━━━━━╸\u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m  25.1MB libmamba                   2.6s\n",
      "Extracting   (5) ━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m      10 atk-1.0                    2.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
      "Downloading  (5) ━━━━━╸\u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m  26.3MB nodejs                     2.7s\n",
      "Extracting   (4) ━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m      11 atk-1.0                    2.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gfonts-conda-forge                                    4.1kB @   1.5kB/s  0.2s\n",
      "[+] 2.9s\n",
      "Downloading  (5) ━━━━━╸\u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m  27.3MB nodejs                     2.8s\n",
      "Extracting   (5) ━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m      11 atk-1.0                    2.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
      "Downloading  (5) ━━━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m  28.6MB nodejs                     2.9s\n",
      "Extracting   (4) ━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m      12 fonts-conda-forge          2.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibmamba                                             1.9MB @ 634.2kB/s  1.1s\n",
      "[+] 3.1s\n",
      "Downloading  (5) ━━━━━━╸\u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m  29.8MB nodejs                     3.0s\n",
      "Extracting   (5) ━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m      12 fonts-conda-forge          2.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
      "Downloading  (5) ━━━━━━╸\u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m  30.4MB python                     3.1s\n",
      "Extracting   (5) ━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m      12 fonts-conda-forge          2.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpython                                              14.0MB @   4.3MB/s  2.4s\n",
      "[+] 3.3s\n",
      "Downloading  (5) ━━━━━━━╸\u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m  31.9MB font-ttf-ubuntu            3.2s\n",
      "Extracting   (5) ━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m      13 fonts-conda-forge          2.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
      "Downloading  (5) ━━━━━━━╸\u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m  33.0MB font-ttf-ubuntu            3.3s\n",
      "Extracting   (4) ━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m      14 libmamba                   2.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
      "Downloading  (5) ━━━━━━━╸\u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m  34.1MB font-ttf-ubuntu            3.4s\n",
      "Extracting   (4) ━━━━╸\u001b[33m━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m      14 libmamba                   3.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibgd                                              308.7kB @  87.4kB/s  0.7s\n",
      "libpng                                             299.2kB @  83.6kB/s  0.3s\n",
      "[+] 3.6s\n",
      "Downloading  (5) ━━━━━━━╸\u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m  35.3MB font-ttf-ubuntu            3.5s\n",
      "Extracting   (6) ━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m      14 libmamba                   3.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
      "Downloading  (5) ━━━━━━━╸\u001b[33m━━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m  36.2MB fribidi                    3.6s\n",
      "Extracting   (5) ━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m      15 libmamba                   3.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
      "Downloading  (5) ━━━━━━━━╸\u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m  37.3MB fribidi                    3.7s\n",
      "Extracting   (5) ━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m      15 libmambapy                 3.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gfribidi                                            115.7kB @  30.0kB/s  0.3s\n",
      "[+] 3.9s\n",
      "Downloading  (5) ━━━━━━━━╸\u001b[33m━━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m  38.7MB font-ttf-ubuntu            3.8s\n",
      "Extracting   (6) ━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m      15 libmambapy                 3.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
      "Downloading  (5) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━━\u001b[0m  40.0MB font-ttf-ubuntu            3.9s\n",
      "Extracting   (6) ━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m      15 libmambapy                 3.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
      "Downloading  (5) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━━\u001b[0m  41.2MB font-ttf-ubuntu            4.0s\n",
      "Extracting   (6) ━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m      15 libmambapy                 3.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpthread-stubs                                        5.7kB @   1.4kB/s  0.2s\n",
      "[+] 4.2s\n",
      "Downloading  (5) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━━\u001b[0m  41.8MB font-ttf-ubuntu            4.1s\n",
      "Extracting   (6) ━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m      16 libpng                     3.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.3s\n",
      "Downloading  (5) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━━\u001b[0m  42.7MB graphite2                  4.2s\n",
      "Extracting   (6) ━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m      16 libpng                     3.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ggraphite2                                          107.3kB @  24.6kB/s  0.3s\n",
      "[+] 4.4s\n",
      "Downloading  (5) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m  44.0MB font-ttf-ubuntu            4.3s\n",
      "Extracting   (7) ━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m      16 libpng                     3.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
      "Downloading  (5) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m  45.3MB font-ttf-ubuntu            4.4s\n",
      "Extracting   (7) ━━━━━╸\u001b[33m━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m      16 libpng                     4.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gfont-ttf-ubuntu                                      2.0MB @ 436.8kB/s  1.9s\n",
      "libtool                                            551.8kB @ 121.6kB/s  1.0s\n",
      "[+] 4.6s\n",
      "Downloading  (5) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m  46.5MB cryptography               4.5s\n",
      "Extracting   (9) ━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m      16 libtool                    4.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibssh2                                            248.2kB @  53.9kB/s  0.2s\n",
      "[+] 4.7s\n",
      "Downloading  (5) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m  47.8MB cryptography               4.6s\n",
      "Extracting   (9) ━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m      17 libtool                    4.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
      "Downloading  (5) ━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━\u001b[0m  48.9MB cryptography               4.7s\n",
      "Extracting   (9) ━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m      17 libtool                    4.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
      "Downloading  (5) ━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━\u001b[0m  50.2MB cryptography               4.8s\n",
      "Extracting   (8) ━━━━━╸\u001b[33m━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m      18 libtool                    4.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibwebp                                            101.0kB @  20.6kB/s  0.3s\n",
      "[+] 5.0s\n",
      "Downloading  (5) ━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━\u001b[0m  51.6MB gtk2                       4.9s\n",
      "Extracting   (9) ━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m      18 libwebp                    4.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
      "Downloading  (5) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m  52.9MB gtk2                       5.0s\n",
      "Extracting   (9) ━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m      18 libwebp                    4.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gnodejs                                              17.6MB @   3.5MB/s  4.3s\n",
      "gtk2                                                 7.9MB @   1.6MB/s  2.1s\n",
      "fonts-conda-ecosystem                                3.7kB @ 709.0 B/s  0.1s\n",
      "[+] 5.2s\n",
      "Downloading  (5) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m  53.7MB cryptography               5.1s\n",
      "Extracting  (10) ━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m      20 libwebp                    4.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gfont-ttf-dejavu-sans-mono                          397.4kB @  76.1kB/s  0.1s\n",
      "[+] 5.3s\n",
      "Downloading  (5) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m  54.4MB cryptography               5.2s\n",
      "Extracting  (11) ━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m      20 libwebp                    4.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
      "Downloading  (5) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m  54.7MB cryptography               5.3s\n",
      "Extracting  (11) ━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m      20 nodejs                     4.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpango                                              444.0kB @  81.2kB/s  0.3s\n",
      "[+] 5.5s\n",
      "Downloading  (5) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m  55.6MB cryptography               5.4s\n",
      "Extracting  (11) ━━━━━━╸\u001b[33m━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m      20 nodejs                     5.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.6s\n",
      "Downloading  (5) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m  55.7MB gettext                    5.5s\n",
      "Extracting  (11) ━━━━━━╸\u001b[33m━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m      21 nodejs                     5.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gxorg-libxext                                        53.8kB @   9.5kB/s  0.7s\n",
      "cryptography                                         1.4MB @ 243.1kB/s  1.1s\n",
      "[+] 5.7s\n",
      "Downloading  (5) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m  56.8MB gettext                    5.6s\n",
      "Extracting  (13) ━━━━━━╸\u001b[33m━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m      21 nodejs                     5.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.8s\n",
      "Downloading  (5) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m  57.5MB gettext                    5.7s\n",
      "Extracting  (13) ━━━━━━╸\u001b[33m━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m      21 pango                      5.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gxorg-libxau                                         13.8kB @   2.4kB/s  0.2s\n",
      "[+] 5.9s\n",
      "Downloading  (5) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m  58.3MB gettext                    5.8s\n",
      "Extracting  (13) ━━━━━━━╸\u001b[33m━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m      22 pango                      5.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibdeflate                                         101.4kB @  17.2kB/s  0.4s\n",
      "[+] 6.0s\n",
      "Downloading  (5) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m  59.4MB gts                        5.9s\n",
      "Extracting  (14) ━━━━━━━╸\u001b[33m━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m      22 pango                      5.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibxcb                                             412.7kB @  68.3kB/s  0.2s\n",
      "[+] 6.1s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━\u001b[0m  60.8MB gts                        6.0s\n",
      "Extracting  (15) ━━━━━━━╸\u001b[33m━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m      22 pango                      5.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.2s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━\u001b[0m  62.0MB gts                        6.1s\n",
      "Extracting  (15) ━━━━━━━╸\u001b[33m━━━━━╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m      22 xorg-libxau                5.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ggts                                                457.1kB @  73.7kB/s  0.3s\n",
      "libglib                                              3.3MB @ 534.9kB/s  1.8s\n",
      "xorg-libxrender                                     34.0kB @   5.4kB/s  0.2s\n",
      "[+] 6.3s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━\u001b[0m  63.3MB font-ttf-source-code-pro   6.2s\n",
      "Extracting  (16) ━━━━━━━╸\u001b[33m━━━━━━╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m      23 xorg-libxau                5.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.4s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m  64.2MB font-ttf-source-code-pro   6.3s\n",
      "Extracting  (16) ━━━━━━━━╸\u001b[33m━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m      24 xorg-libxau                5.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.5s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m  64.8MB font-ttf-source-code-pro   6.4s\n",
      "Extracting  (16) ━━━━━━━━╸\u001b[33m━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m      24 xorg-libxau                6.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gfont-ttf-source-code-pro                           700.8kB @ 107.5kB/s  0.3s\n",
      "[+] 6.6s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m  65.9MB gettext                    6.5s\n",
      "Extracting  (17) ━━━━━━━━╸\u001b[33m━━━━━━╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m      24 xorg-libxrender            6.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ggettext                                              4.7MB @ 705.8kB/s  1.4s\n",
      "jpeg                                               484.0kB @  73.1kB/s  0.3s\n",
      "[+] 6.7s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m  66.7MB freetype                   6.6s\n",
      "Extracting  (18) ━━━━━━━━╸\u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m      25 xorg-libxrender            6.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gkrb5                                                 1.6MB @ 244.6kB/s  1.0s\n",
      "font-ttf-inconsolata                                96.5kB @  14.3kB/s  0.1s\n",
      "[+] 6.8s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m  66.9MB freetype                   6.7s\n",
      "Extracting  (19) ━━━━━━━━╸\u001b[33m━━━━━━━╸\u001b[0m\u001b[90m━━━━━━\u001b[0m      25 xorg-libxrender            6.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gxorg-libsm                                          26.6kB @   3.9kB/s  0.2s\n",
      "[+] 6.9s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m  67.1MB freetype                   6.8s\n",
      "Extracting  (21) ━━━━━━━━╸\u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m      25 xorg-libxrender            6.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ggiflib                                              80.1kB @  11.6kB/s  0.4s\n",
      "[+] 7.0s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m  67.4MB freetype                   6.9s\n",
      "Extracting  (22) ━━━━━━━━╸\u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m      25 cryptography               6.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.1s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m  67.7MB graphviz                   7.0s\n",
      "Extracting  (21) ━━━━━━━━╸\u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m      26 cryptography               6.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.2s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m  68.4MB graphviz                   7.1s\n",
      "Extracting  (21) ━━━━━━━━╸\u001b[33m━━━━━━━━╸\u001b[0m\u001b[90m━━━━━\u001b[0m      26 cryptography               6.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gfontconfig                                         364.1kB @  50.7kB/s  0.3s\n",
      "[+] 7.3s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m  69.2MB graphviz                   7.2s\n",
      "Extracting  (22) ━━━━━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m      26 cryptography               6.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.4s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m  69.7MB graphviz                   7.3s\n",
      "Extracting  (22) ━━━━━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━━\u001b[0m      26 font-ttf-dejavu-sans-mono  6.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gfreetype                                           638.6kB @  86.3kB/s  0.8s\n",
      "mamba                                               48.5kB @   6.6kB/s  0.2s\n",
      "xorg-kbproto                                        27.4kB @   3.7kB/s  0.6s\n",
      "[+] 7.5s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m  70.3MB libnghttp2                 7.4s\n",
      "Extracting  (24) ━━━━━━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m      27 font-ttf-dejavu-sans-mono  7.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.6s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m  70.9MB libnghttp2                 7.5s\n",
      "Extracting  (24) ━━━━━━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m      27 font-ttf-dejavu-sans-mono  7.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 7.7s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m  71.9MB libnghttp2                 7.6s\n",
      "Extracting  (24) ━━━━━━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m      27 font-ttf-dejavu-sans-mono  7.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Ggraphviz                                             2.5MB @ 318.0kB/s  1.0s\n",
      "[+] 7.8s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m  73.1MB libnghttp2                 7.7s\n",
      "Extracting  (25) ━━━━━━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m      27 font-ttf-inconsolata       7.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibnghttp2                                         985.3kB @ 125.8kB/s  0.4s\n",
      "[+] 7.9s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m  74.3MB cairo                      7.8s\n",
      "Extracting  (26) ━━━━━━━━━╸\u001b[33m━━━━━━━━━╸\u001b[0m\u001b[90m━━━\u001b[0m      27 font-ttf-inconsolata       7.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gcairo                                                1.8MB @ 226.6kB/s  0.5s\n",
      "[+] 8.0s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m  75.2MB harfbuzz                   7.9s\n",
      "Extracting  (27) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m      27 font-ttf-inconsolata       7.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.1s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m  76.3MB harfbuzz                   8.0s\n",
      "Extracting  (27) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m      27 font-ttf-inconsolata       7.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gxorg-xextproto                                      28.3kB @   3.5kB/s  0.2s\n",
      "[+] 8.2s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m  77.3MB harfbuzz                   8.1s\n",
      "Extracting  (28) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m      27 font-ttf-source-code-pro   7.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.3s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m  78.5MB harfbuzz                   8.2s\n",
      "Extracting  (28) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━╸\u001b[0m\u001b[90m━━\u001b[0m      27 font-ttf-source-code-pro   7.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpcre2                                                2.4MB @ 284.4kB/s  1.0s\n",
      "[+] 8.4s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m  79.8MB libarchive                 8.3s\n",
      "Extracting  (29) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m      27 font-ttf-source-code-pro   7.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.5s\n",
      "Downloading  (5) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m  81.1MB libarchive                 8.4s\n",
      "Extracting  (28) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m      28 font-ttf-source-code-pro   8.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gxorg-libx11                                        983.5kB @ 115.7kB/s  0.3s\n",
      "pycurl                                              77.8kB @   9.1kB/s  0.2s\n",
      "[+] 8.6s\n",
      "Downloading  (3) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m  82.4MB libarchive                 8.5s\n",
      "Extracting  (29) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━━╸\u001b[0m\u001b[90m━\u001b[0m      29 font-ttf-ubuntu            8.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gharfbuzz                                             2.4MB @ 277.3kB/s  0.8s\n",
      "libarchive                                           2.0MB @ 233.2kB/s  0.9s\n",
      "[+] 8.7s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m  83.1MB librsvg                    8.6s\n",
      "Extracting  (31) ━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━━\u001b[0m      29 font-ttf-ubuntu            8.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.8s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m  83.2MB librsvg                    8.7s\n",
      "Extracting  (30) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m      30 font-ttf-ubuntu            8.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 8.9s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m  83.3MB librsvg                    8.8s\n",
      "Extracting  (29) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m      31 font-ttf-ubuntu            8.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.0s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  83.5MB librsvg                    8.9s\n",
      "Extracting  (29) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m      31 fontconfig                 8.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.1s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  83.5MB librsvg                    9.0s\n",
      "Extracting  (29) ━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━━\u001b[0m      31 fontconfig                 8.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.2s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  83.6MB librsvg                    9.1s\n",
      "Extracting  (28) ━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━\u001b[0m      32 fontconfig                 8.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.3s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  83.8MB librsvg                    9.2s\n",
      "Extracting  (28) ━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━\u001b[0m      32 fontconfig                 8.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.4s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  83.8MB librsvg                    9.3s\n",
      "Extracting  (27) ━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━\u001b[0m      33 freetype                   8.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.5s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  84.1MB librsvg                    9.4s\n",
      "Extracting  (26) ━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━\u001b[0m      34 freetype                   9.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.6s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  84.1MB librsvg                    9.5s\n",
      "Extracting  (26) ━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━━\u001b[0m      34 freetype                   9.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.7s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  84.1MB librsvg                    9.6s\n",
      "Extracting  (25) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m      35 freetype                   9.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.8s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  84.5MB librsvg                    9.7s\n",
      "Extracting  (24) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m      36 gts                        9.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 9.9s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  84.5MB librsvg                    9.8s\n",
      "Extracting  (24) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m      36 gts                        9.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.0s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  84.5MB librsvg                    9.9s\n",
      "Extracting  (24) ━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━━\u001b[0m      36 gts                        9.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.1s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  84.8MB librsvg                   10.0s\n",
      "Extracting  (22) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m      38 gts                        9.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.2s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  84.8MB librsvg                   10.1s\n",
      "Extracting  (22) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m      38 harfbuzz                   9.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.3s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  85.0MB librsvg                   10.2s\n",
      "Extracting  (22) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m      38 harfbuzz                   9.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.4s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  85.0MB librsvg                   10.3s\n",
      "Extracting  (21) ━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━━\u001b[0m      39 harfbuzz                   9.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.5s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  85.1MB librsvg                   10.4s\n",
      "Extracting  (20) ━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━\u001b[0m      40 harfbuzz                  10.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.6s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  85.3MB librsvg                   10.5s\n",
      "Extracting  (20) ━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━\u001b[0m      40 krb5                      10.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.7s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  85.4MB librsvg                   10.6s\n",
      "Extracting  (20) ━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━\u001b[0m      40 krb5                      10.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.8s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  85.4MB librsvg                   10.7s\n",
      "Extracting  (18) ━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━\u001b[0m      42 cairo                     10.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 10.9s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  85.7MB librsvg                   10.8s\n",
      "Extracting  (18) ━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━\u001b[0m      42 cairo                     10.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.0s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  85.7MB librsvg                   10.9s\n",
      "Extracting  (18) ━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━━\u001b[0m      42 cairo                     10.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.1s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  85.7MB librsvg                   11.0s\n",
      "Extracting  (17) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m      43 cairo                     10.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.2s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  86.1MB librsvg                   11.1s\n",
      "Extracting  (17) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m      43 cryptography              10.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.3s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  86.5MB librsvg                   11.2s\n",
      "Extracting  (16) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m      44 cryptography              10.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.4s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m  86.9MB librsvg                   11.3s\n",
      "Extracting  (15) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m      45 cryptography              10.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.5s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  87.1MB librsvg                   11.4s\n",
      "Extracting  (15) ━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━━\u001b[0m      45 cryptography              11.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.6s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  87.3MB librsvg                   11.5s\n",
      "Extracting  (14) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m      46 font-ttf-dejavu-sans-mono 11.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.7s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  88.3MB librsvg                   11.6s\n",
      "Extracting  (13) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m      47 cairo                     11.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.8s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  88.9MB librsvg                   11.7s\n",
      "Extracting  (13) ━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━━\u001b[0m      47 cairo                     11.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 11.9s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  89.1MB librsvg                   11.8s\n",
      "Extracting  (12) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m      48 cairo                     11.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.0s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  89.6MB librsvg                   11.9s\n",
      "Extracting  (11) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m      49 cairo                     11.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.1s\n",
      "Downloading  (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m  90.2MB librsvg                   12.0s\n",
      "Extracting  (11) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m      49 cryptography              11.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibrsvg                                              9.8MB @ 805.2kB/s  5.9s\n",
      "[+] 12.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting  (11) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m      50 cryptography              11.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting  (11) ━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━━\u001b[0m      50 cryptography              11.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting  (10) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      51 cryptography              11.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting  (10) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      51 freetype                  12.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (9) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      52 freetype                  12.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      53 freetype                  12.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (8) ━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━━\u001b[0m      53 freetype                  12.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 12.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (6) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m      55 harfbuzz                  12.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (6) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m      55 harfbuzz                  12.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (6) ━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━━\u001b[0m      55 harfbuzz                  12.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (4) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      57 harfbuzz                  12.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (4) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      57 libarchive                12.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (4) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      57 libarchive                12.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.5s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      58 libarchive                13.0s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.6s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      58 libarchive                13.1s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.7s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      58 librsvg                   13.2s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.8s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      58 librsvg                   13.3s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 13.9s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (3) ━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━━\u001b[0m      58 librsvg                   13.4s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.0s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      59 librsvg                   13.5s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.1s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      59 harfbuzz                  13.6s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.2s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (2) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      59 harfbuzz                  13.7s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.3s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting   (1) ━━━━━━━━━━━━━━━━━━━━━╸\u001b[33m━\u001b[0m      60 harfbuzz                  13.8s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 14.4s\n",
      "Downloading      ━━━━━━━━━━━━━━━━━━━━━━━  90.7MB                           12.1s\n",
      "Extracting       ━━━━━━━━━━━━━━━━━━━━━━━      61                           13.9s\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25hPreparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: - \n",
      "| \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "!mamba install -y graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0074619-5a56-43c0-8923-bec6b383237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version \u001b[39;1m^0.20.1\u001b[39;22m for \u001b[36mgraphviz\u001b[39m\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[39m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(0.3s)\u001b[39;22m\n",
      "\n",
      "\u001b[34mWriting lock file\u001b[39m\n",
      "\n",
      "No dependencies to install or update\n"
     ]
    }
   ],
   "source": [
    "!poetry add --group dev graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f916e98-9a1d-43a0-bca5-957e148c105c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring colorama: markers 'sys_platform == \"win32\" and python_full_version == \"3.10.6\" or platform_system == \"Windows\" and python_full_version == \"3.10.6\"' don't match your environment\n",
      "Requirement already satisfied: astroid==2.12.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.12.13)\n",
      "Requirement already satisfied: boto3==1.26.17 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.26.17)\n",
      "Requirement already satisfied: botocore==1.29.17 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.29.17)\n",
      "Requirement already satisfied: certifi==2022.9.24 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer==2.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.1.1)\n",
      "Requirement already satisfied: click==8.1.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (8.1.3)\n",
      "Requirement already satisfied: dill==0.3.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (0.3.6)\n",
      "Requirement already satisfied: feedparser==6.0.10 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (6.0.10)\n",
      "Requirement already satisfied: idna==3.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (3.4)\n",
      "Requirement already satisfied: isort==5.10.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 31)) (5.10.1)\n",
      "Requirement already satisfied: jmespath==1.0.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 34)) (1.0.1)\n",
      "Requirement already satisfied: joblib==1.2.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 37)) (1.2.0)\n",
      "Requirement already satisfied: lazy-object-proxy==1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 40)) (1.8.0)\n",
      "Requirement already satisfied: mccabe==0.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 60)) (0.7.0)\n",
      "Requirement already satisfied: metaflow==2.7.14 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 63)) (2.7.14)\n",
      "Requirement already satisfied: nltk==3.7 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 66)) (3.7)\n",
      "Requirement already satisfied: numpy==1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 69)) (1.23.5)\n",
      "Requirement already satisfied: pandas==1.5.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 98)) (1.5.2)\n",
      "Requirement already satisfied: pendulum==2.1.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 126)) (2.1.2)\n",
      "Requirement already satisfied: platformdirs==2.5.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 148)) (2.5.4)\n",
      "Requirement already satisfied: pylint==2.15.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 151)) (2.15.6)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 154)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 157)) (2022.6)\n",
      "Requirement already satisfied: pytzdata==2020.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 160)) (2020.1)\n",
      "Requirement already satisfied: regex==2022.10.31 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 163)) (2022.10.31)\n",
      "Requirement already satisfied: requests==2.28.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 252)) (2.28.1)\n",
      "Requirement already satisfied: s3transfer==0.6.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 255)) (0.6.0)\n",
      "Requirement already satisfied: sgmllib3k==1.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 258)) (1.0.0)\n",
      "Requirement already satisfied: six==1.16.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 260)) (1.16.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 263)) (2.0.1)\n",
      "Requirement already satisfied: tomlkit==0.11.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 266)) (0.11.6)\n",
      "Requirement already satisfied: tqdm==4.64.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 269)) (4.64.1)\n",
      "Requirement already satisfied: urllib3==1.26.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 272)) (1.26.13)\n",
      "Requirement already satisfied: wrapt==1.14.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 275)) (1.14.1)\n"
     ]
    }
   ],
   "source": [
    "!poetry export -f requirements.txt --output requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c9294a07-2e65-44d0-bd12-e1b3bb7c7012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.14\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mFeedsFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:jovyan\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mVisualizing the flow as a GraphViz graph\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[22m    Try piping the output to 'dot -Tpng -o graph.png' to produce an actual image.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data\n",
    "!python src/data/feeds_flow.py output-dot | dot -o data/feeds.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c22ea76f-25d1-4a0c-849e-36922e2fa45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 6.0.1 (20220911.2005)\n",
       " -->\n",
       "<!-- Title: FeedsFlow Pages: 1 -->\n",
       "<svg width=\"202pt\" height=\"342pt\"\n",
       " viewBox=\"0.00 0.00 202.00 342.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 338)\">\n",
       "<title>FeedsFlow</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-338 198,-338 198,4 -4,4\"/>\n",
       "<!-- start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>start</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"46,-296.5 46,-333.5 148,-333.5 148,-296.5 46,-296.5\"/>\n",
       "<text text-anchor=\"start\" x=\"54\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">start</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"95,-296.5 95,-333.5\"/>\n",
       "<text text-anchor=\"start\" x=\"103\" y=\"-312.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">foreach</text>\n",
       "</g>\n",
       "<!-- fetch_feed_data -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>fetch_feed_data</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"11.5,-222.5 11.5,-259.5 182.5,-259.5 182.5,-222.5 11.5,-222.5\"/>\n",
       "<text text-anchor=\"start\" x=\"19.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">fetch_feed_data</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"138.5,-222.5 138.5,-259.5\"/>\n",
       "<text text-anchor=\"start\" x=\"146.5\" y=\"-238.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">linear</text>\n",
       "</g>\n",
       "<!-- start&#45;&gt;fetch_feed_data -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>start&#45;&gt;fetch_feed_data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-296.2C97,-288.18 97,-278.52 97,-269.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-269.59 97,-259.59 93.5,-269.59 100.5,-269.59\"/>\n",
       "</g>\n",
       "<!-- feeds_aggregate -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>feeds_aggregate</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"13.5,-148.5 13.5,-185.5 180.5,-185.5 180.5,-148.5 13.5,-148.5\"/>\n",
       "<text text-anchor=\"start\" x=\"21.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">feeds_aggregate</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"145.5,-148.5 145.5,-185.5\"/>\n",
       "<text text-anchor=\"start\" x=\"153.5\" y=\"-164.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">join</text>\n",
       "</g>\n",
       "<!-- fetch_feed_data&#45;&gt;feeds_aggregate -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>fetch_feed_data&#45;&gt;feeds_aggregate</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-222.2C97,-214.18 97,-204.52 97,-195.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-195.59 97,-185.59 93.5,-195.59 100.5,-195.59\"/>\n",
       "</g>\n",
       "<!-- preprocess_pandas -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>preprocess_pandas</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-74.5 0,-111.5 194,-111.5 194,-74.5 0,-74.5\"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-90.3\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">preprocess_pandas</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"150,-74.5 150,-111.5\"/>\n",
       "<text text-anchor=\"start\" x=\"158\" y=\"-90.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">linear</text>\n",
       "</g>\n",
       "<!-- feeds_aggregate&#45;&gt;preprocess_pandas -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>feeds_aggregate&#45;&gt;preprocess_pandas</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-148.2C97,-140.18 97,-130.52 97,-121.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-121.59 97,-111.59 93.5,-121.59 100.5,-121.59\"/>\n",
       "</g>\n",
       "<!-- end -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>end</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"58,-0.5 58,-37.5 136,-37.5 136,-0.5 58,-0.5\"/>\n",
       "<text text-anchor=\"start\" x=\"66\" y=\"-16.3\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"14.00\">end</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"101,-0.5 101,-37.5\"/>\n",
       "<text text-anchor=\"start\" x=\"109\" y=\"-16.5\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\">end</text>\n",
       "</g>\n",
       "<!-- preprocess_pandas&#45;&gt;end -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>preprocess_pandas&#45;&gt;end</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97,-74.2C97,-66.18 97,-56.52 97,-47.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.5,-47.59 97,-37.59 93.5,-47.59 100.5,-47.59\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0xffff74780fa0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "graphviz.Source.from_file('data/feeds.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb65c3-ca65-4d3e-924a-9082a1b254fa",
   "metadata": {},
   "source": [
    "## Writing results\n",
    "\n",
    "Finally we will use the generated Dataframe to save parquet generated files that can be used on next steps. To do that the chosen engine will be [fastparquet](https://fastparquet.readthedocs.io/en/latest/index.html), which will allow us to update the data as the script runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bae40d3c-2e96-4b09-a866-b26ac221d18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version \u001b[39;1m^2022.11.0\u001b[39;22m for \u001b[36mfastparquet\u001b[39m\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[39m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[39m \u001b[39;2m(0.7s)\u001b[39;22m\n",
      "\n",
      "\u001b[34mWriting lock file\u001b[39m\n",
      "\n",
      "No dependencies to install or update\n"
     ]
    }
   ],
   "source": [
    "!poetry add fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28ae2149-c746-411a-89d3-7884cfdc2304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring colorama: markers 'sys_platform == \"win32\" and python_full_version == \"3.10.6\" or platform_system == \"Windows\" and python_full_version == \"3.10.6\"' don't match your environment\n",
      "Requirement already satisfied: astroid==2.12.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.12.13)\n",
      "Requirement already satisfied: boto3==1.26.17 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.26.17)\n",
      "Requirement already satisfied: botocore==1.29.17 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.29.17)\n",
      "Requirement already satisfied: certifi==2022.9.24 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer==2.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.1.1)\n",
      "Requirement already satisfied: click==8.1.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (8.1.3)\n",
      "Collecting cramjam==2.6.2\n",
      "  Downloading cramjam-2.6.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill==0.3.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 82)) (0.3.6)\n",
      "Collecting fastparquet==2022.11.0\n",
      "  Downloading fastparquet-2022.11.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: feedparser==6.0.10 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 111)) (6.0.10)\n",
      "Collecting fsspec==2022.11.0\n",
      "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna==3.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 117)) (3.4)\n",
      "Requirement already satisfied: isort==5.10.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 120)) (5.10.1)\n",
      "Requirement already satisfied: jmespath==1.0.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 123)) (1.0.1)\n",
      "Requirement already satisfied: joblib==1.2.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 126)) (1.2.0)\n",
      "Requirement already satisfied: lazy-object-proxy==1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 129)) (1.8.0)\n",
      "Requirement already satisfied: mccabe==0.7.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 149)) (0.7.0)\n",
      "Requirement already satisfied: metaflow==2.7.14 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 152)) (2.7.14)\n",
      "Requirement already satisfied: nltk==3.7 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 155)) (3.7)\n",
      "Requirement already satisfied: numpy==1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 158)) (1.23.5)\n",
      "Requirement already satisfied: packaging==21.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 187)) (21.3)\n",
      "Requirement already satisfied: pandas==1.5.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 190)) (1.5.2)\n",
      "Requirement already satisfied: pendulum==2.1.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 218)) (2.1.2)\n",
      "Requirement already satisfied: platformdirs==2.5.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 240)) (2.5.4)\n",
      "Requirement already satisfied: pylint==2.15.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 243)) (2.15.6)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 246)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 249)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 252)) (2022.6)\n",
      "Requirement already satisfied: pytzdata==2020.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 255)) (2020.1)\n",
      "Requirement already satisfied: regex==2022.10.31 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 258)) (2022.10.31)\n",
      "Requirement already satisfied: requests==2.28.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 347)) (2.28.1)\n",
      "Requirement already satisfied: s3transfer==0.6.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 350)) (0.6.0)\n",
      "Requirement already satisfied: sgmllib3k==1.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 353)) (1.0.0)\n",
      "Requirement already satisfied: six==1.16.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 355)) (1.16.0)\n",
      "Requirement already satisfied: tomli==2.0.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 358)) (2.0.1)\n",
      "Requirement already satisfied: tomlkit==0.11.6 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 361)) (0.11.6)\n",
      "Requirement already satisfied: tqdm==4.64.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 364)) (4.64.1)\n",
      "Requirement already satisfied: urllib3==1.26.13 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 367)) (1.26.13)\n",
      "Requirement already satisfied: wrapt==1.14.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 370)) (1.14.1)\n",
      "Installing collected packages: fsspec, cramjam, fastparquet\n",
      "Successfully installed cramjam-2.6.2 fastparquet-2022.11.0 fsspec-2022.11.0\n"
     ]
    }
   ],
   "source": [
    "!poetry export -f requirements.txt --output requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad030f48-bf0d-4d5e-a038-08abf3b925ac",
   "metadata": {},
   "source": [
    "Following data science layout, parquet file will be stored in `data` directory. Let's use the configuration layout of filesystem URL, because we can change it later when we add remote features or move data to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e89404a0-c0f8-49c3-80d9-8440574fdc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/data/news'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.environ['FILEPATH']= os.path.join(os.path.abspath(\"./\"), 'data/news')\n",
    "os.environ['FILEPATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9705b285-a61a-45a3-a62e-61dda3218a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"$FILEPATH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fdd468b7-cb49-4d45-b4c3-4a9ef900bf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FILENAME=news.parquet\n"
     ]
    }
   ],
   "source": [
    "%env FILENAME=news.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "340393fa-a359-4c6f-ae03-2f5b2b1b0bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/data/feeds_flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/data/feeds_flow.py\n",
    "# %load src/data/feeds_flow.py\n",
    "import os\n",
    "import feedparser\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "import pendulum\n",
    "\n",
    "from metaflow import FlowSpec, step\n",
    "\n",
    "class FeedsFlow(FlowSpec):\n",
    "\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.feeds_url = [\n",
    "            'https://feeds.folha.uol.com.br/emcimadahora/rss091.xml',\n",
    "            'https://g1.globo.com/rss/g1/',\n",
    "            'https://g1.globo.com/rss/g1/brasil'\n",
    "        ]\n",
    "        self.next(self.fetch_feed_data, foreach='feeds_url')\n",
    "\n",
    "    @step\n",
    "    def fetch_feed_data(self):\n",
    "        \n",
    "        print(f\"Downloading from url {self.input}\")\n",
    "        blog_feed = feedparser.parse(self.input)\n",
    "\n",
    "        posts = blog_feed.entries  \n",
    "        post_list = []\n",
    "\n",
    "        for post in posts:\n",
    "            post_dict = dict()\n",
    "\n",
    "            post_dict[\"TITLE\"] = post.title\n",
    "            post_dict[\"CONTENT\"] = post.summary\n",
    "            post_dict[\"LINK\"] = post.link\n",
    "            post_dict[\"TIME_PUBLISHED\"] = post.published\n",
    "            # post_dict[\"TAGS\"] = [tag.term for tag in post.tags]\n",
    "            \n",
    "            # First date conversion try:\n",
    "            dt = None\n",
    "            try:\n",
    "                dt = pendulum.from_format(post.published, 'DD MMM YYYY HH:mm:ss ZZ') \n",
    "            except ValueError as e:\n",
    "                dt = pendulum.from_format(post.published, 'ddd, DD MMM YYYY HH:mm:ss ZZ')\n",
    "            except ValueError as e:\n",
    "                print(f\"Formating error!\\n{e}\")\n",
    "                continue\n",
    "            post_dict['PUBLISHED'] = dt.isoformat()\n",
    "            post_dict['PUBLISHED_DATE'] = dt.to_date_string()\n",
    "\n",
    "            post_list.append(post_dict)\n",
    "        self.posts = pd.DataFrame(post_list)        \n",
    "        self.next(self.feeds_aggregate)\n",
    "\n",
    "    @step\n",
    "    def feeds_aggregate(self, inputs):\n",
    "        self.results = pd.concat([input.posts for input in inputs])\n",
    "        self.next(self.preprocess_pandas)\n",
    "              \n",
    "    @step\n",
    "    def preprocess_pandas(self):\n",
    "        stop = set(stopwords.words('portuguese') + list(string.punctuation))\n",
    "        stop.update(['http', 'pro', 'https', 't.', 'co'])\n",
    "\n",
    "        def preprocess(words):\n",
    "            # Remove HTML marks\n",
    "            words = re.sub('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', '', words)\n",
    "            tokens = word_tokenize(words)\n",
    "            tokens = [word for word in tokens if word not in stop]\n",
    "            tokens = [word for word in tokens if re.search(r'\\w+', word) and len(word) > 2]\n",
    "            return tokens\n",
    "    \n",
    "        self.results['token_set'] = self.results.apply(lambda row: preprocess(row.CONTENT.lower()), axis=1)\n",
    "        print(\"Tokenization finished!\")\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        filepath = os.path.join(os.environ['FILEPATH'], os.environ['FILENAME'])\n",
    "        print(f'Writing data back to parquet at {filepath}...')\n",
    "        columns = ['TITLE', 'CONTENT', 'LINK', 'PUBLISHED', 'PUBLISHED_DATE']\n",
    "        # Partition news by date\n",
    "        try:\n",
    "            self.results[columns].to_parquet(filepath, append=True, engine='fastparquet', index=False, partition_cols=['PUBLISHED_DATE'])\n",
    "        except FileNotFoundError as e:\n",
    "            # Create file if it does not exists\n",
    "            self.results[columns].to_parquet(filepath, append=False, engine='fastparquet', index=False, partition_cols=['PUBLISHED_DATE'])\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    FeedsFlow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2500f72-4bac-4c4e-b0a1-cc93f5f28a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.14\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mFeedsFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:jovyan\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:44.210 \u001b[0m\u001b[1mWorkflow starting (run-id 1669663064156463):\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:44.234 \u001b[0m\u001b[32m[1669663064156463/start/1 (pid 1633)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:44.887 \u001b[0m\u001b[32m[1669663064156463/start/1 (pid 1633)] \u001b[0m\u001b[1mForeach yields 3 child steps.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:44.887 \u001b[0m\u001b[32m[1669663064156463/start/1 (pid 1633)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:44.925 \u001b[0m\u001b[32m[1669663064156463/fetch_feed_data/2 (pid 1637)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:44.941 \u001b[0m\u001b[32m[1669663064156463/fetch_feed_data/3 (pid 1638)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:44.958 \u001b[0m\u001b[32m[1669663064156463/fetch_feed_data/4 (pid 1639)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:45.785 \u001b[0m\u001b[32m[1669663064156463/fetch_feed_data/2 (pid 1637)] \u001b[0m\u001b[22mDownloading from url https://feeds.folha.uol.com.br/emcimadahora/rss091.xml\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:45.876 \u001b[0m\u001b[32m[1669663064156463/fetch_feed_data/3 (pid 1638)] \u001b[0m\u001b[22mDownloading from url https://g1.globo.com/rss/g1/\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:45.936 \u001b[0m\u001b[32m[1669663064156463/fetch_feed_data/4 (pid 1639)] \u001b[0m\u001b[22mDownloading from url https://g1.globo.com/rss/g1/brasil\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:46.185 \u001b[0m\u001b[32m[1669663064156463/fetch_feed_data/2 (pid 1637)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:46.305 \u001b[0m\u001b[32m[1669663064156463/fetch_feed_data/3 (pid 1638)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:46.351 \u001b[0m\u001b[32m[1669663064156463/fetch_feed_data/4 (pid 1639)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:46.386 \u001b[0m\u001b[32m[1669663064156463/feeds_aggregate/5 (pid 1649)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:47.087 \u001b[0m\u001b[32m[1669663064156463/feeds_aggregate/5 (pid 1649)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:47.117 \u001b[0m\u001b[32m[1669663064156463/preprocess_pandas/6 (pid 1653)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:47.782 \u001b[0m\u001b[32m[1669663064156463/preprocess_pandas/6 (pid 1653)] \u001b[0m\u001b[22mTokenization finished!\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:47.953 \u001b[0m\u001b[32m[1669663064156463/preprocess_pandas/6 (pid 1653)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:47.994 \u001b[0m\u001b[32m[1669663064156463/end/7 (pid 1663)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:48.554 \u001b[0m\u001b[32m[1669663064156463/end/7 (pid 1663)] \u001b[0m\u001b[22mWriting data back to parquet at /home/jovyan/data/news/news.parquet...\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:48.855 \u001b[0m\u001b[32m[1669663064156463/end/7 (pid 1663)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-11-28 19:17:48.862 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python src/data/feeds_flow.py run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337029f8-b3a2-42cd-9f9e-b14818266ded",
   "metadata": {},
   "source": [
    "Now we can load and see how the results are stored back on parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c31cf9-c658-4a81-9f98-d101813a043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "filepath = os.path.join(os.environ['FILEPATH'], os.environ['FILENAME'])\n",
    "test = pd.read_parquet(filepath"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
